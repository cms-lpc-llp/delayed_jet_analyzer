{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "# check the affect of HEM issue on signal yield in run 2\n",
    "# check the signal yield before and after removal of jets in problematic region\n",
    "import ROOT as rt\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import awkward\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/af/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "sys.path.append('/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/python/')\n",
    "from helper import make_datacard_2sig, make_datacard_2tag, weight_calc\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "from helper_functions import deltaR, deltaPhi\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "mass = [15, 40, 55]\n",
    "\n",
    "\n",
    "old_ctau = {\n",
    "#     'STodd_ms3p0':[100,500],\n",
    "#     'SToEE_ms0p4':[10,50],\n",
    "#     'SToGammaGamma_ms0p4':[10,50],\n",
    "#     'SToKPlusKMinus_ms1p5':[38,187],\n",
    "#     'SToK0K0_ms1p5':[38,187],\n",
    "#     'SToPi0Pi0_ms0p4':[10,50],\n",
    "#     'SToPi0Pi0_ms1p0':[25,125],\n",
    "#     'SToPiPlusPiMinus_ms0p4':[10,50],\n",
    "#     'SToPiPlusPiMinus_ms1p0':[25,125],\n",
    "#     'STodd_ms7':[100, 1000, 10000, 100000],\n",
    "#     'STodd_ms15':[100, 1000, 10000, 100000],\n",
    "#     'STodd_ms40':[100, 1000, 10000, 100000],\n",
    "#     'STodd_ms55':[100, 1000, 10000, 100000],\n",
    "    \n",
    "    'STodd_ms7':[1000],\n",
    "    'STodd_ms15':[1000],\n",
    "    'STodd_ms40':[1000],\n",
    "    'STodd_ms55':[1000],\n",
    "#     'SToTauTau_ms7':[100, 1000, 10000, 100000],\n",
    "#     'SToTauTau_ms15':[100, 1000, 10000, 100000],\n",
    "#     'SToTauTau_ms40':[100, 1000, 10000, 100000],\n",
    "#     'SToTauTau_ms55':[100, 1000, 10000, 100000],\n",
    "#     'SToBB_ms15':[100, 1000, 10000, 100000],\n",
    "#     'SToBB_ms40':[100, 1000, 10000, 100000],\n",
    "#     'SToBB_ms55':[100, 1000, 10000, 100000],\n",
    "#     'SToEE_ms4p0':[100,500],\n",
    "#     'SToGammaGamma_ms4p0':[100,500],\n",
    "#     'SToPiPlusPiMinus_ms4p0':[100,500],\n",
    "    \n",
    "}\n",
    "\n",
    "# prod = ['ggH', 'VBFH','ZH', 'WH', 'ttH','ggZH']\n",
    "prod=['ggH']\n",
    "\n",
    "ntupler_version = 'V1p17/'\n",
    "mc_path = {}\n",
    "analyzer_version = 'v1/v168/'\n",
    "mc_central_path = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "\n",
    "\n",
    "for p in prod:\n",
    "#     if 'WH' in p:continue\n",
    "    for k in old_ctau.keys():\n",
    "        for ct in old_ctau[k]:\n",
    "            key = 'MC_'+p+'_'+k + '_'+str(ct)\n",
    "            if (p == 'ggH' or p == 'VBFH') and ('ms7' in k or 'ms15' in k or 'ms40' in k or 'ms55' in k) and not (p =='VBFH' and 'dd' in k):\n",
    "                mass = k[k.find('ms')+2:]\n",
    "                if 'dd' in k and p == 'ggH':fpath[key] = mc_central_path+p+'_HToSSTodddd_MH-125_MS-'+mass+'_ctau-'+str(ct)+'_TuneCP5_13TeV-powheg-pythia8_59740pb_weighted.root'\n",
    "            \n",
    "            if not os.path.exists(fpath[key]):print(key, fpath[key])\n",
    "            \n",
    "\n",
    "            \n",
    "# mass = [15, 40, 55]\n",
    "# if not decay == 'bbbb': mass = [7, 15, 40, 55]\n",
    "\n",
    "# OLD_CTAU = np.array([100, 1000, 10000, 100000])#in mm\n",
    "\n",
    "# ntupler_version = 'V1p17/'\n",
    "\n",
    "\n",
    "                     \n",
    "NEvents = {}\n",
    "# NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    root_dir = uproot.open(v) \n",
    "    if not root_dir: \n",
    "        print(k, \"zombie\")\n",
    "        continue\n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "#     NEvents[k] = root_dir['NEvents'][1]\n",
    "    NEvents[k] = root_dir['NEvents']._fEntries\n",
    "#     print(k)\n",
    "#     if not 'data' in k: \n",
    "#         print(k, root_dir['NEvents']._fEntries)\n",
    "\n",
    "\n",
    "root_dir = uproot.open('/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/HiggsPtWeights/ZHToggZH_HiggsPtReweight.root') \n",
    "h_reweight = root_dir['higgsPthiggsEta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc with different hit vetoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category 0, remove jets in HEM 0\n",
      "category 0, remove jets in HEM 1\n",
      "MC_ggH_STodd_ms7_1000 \t 42.7 +- 7.29 \t 41.84 +- 7.24 \t -0.020201385021209717\n",
      "MC_ggH_STodd_ms15_1000 \t 92.31 +- 10.34 \t 91.47 +- 10.3 \t -0.0090714693069458\n",
      "MC_ggH_STodd_ms40_1000 \t 170.86 +- 14.19 \t 167.27 +- 14.03 \t -0.021000385284423828\n",
      "MC_ggH_STodd_ms55_1000 \t 12.77 +- 3.8 \t 12.77 +- 3.8 \t 0.0\n",
      "category 1, remove jets in HEM 0\n",
      "category 1, remove jets in HEM 1\n",
      "MC_ggH_STodd_ms7_1000 \t 224.11 +- 16.22 \t 220.13 +- 16.08 \t -0.01773935556411743\n",
      "MC_ggH_STodd_ms15_1000 \t 429.07 +- 22.89 \t 421.86 +- 22.66 \t -0.016796529293060303\n",
      "MC_ggH_STodd_ms40_1000 \t 439.48 +- 22.59 \t 436.69 +- 22.52 \t -0.006332755088806152\n",
      "MC_ggH_STodd_ms55_1000 \t 31.38 +- 6.0 \t 30.19 +- 5.88 \t -0.037999629974365234\n",
      "category 2, remove jets in HEM 0\n",
      "category 2, remove jets in HEM 1\n",
      "MC_ggH_STodd_ms7_1000 \t 340.99 +- 20.66 \t 337.51 +- 20.58 \t -0.010214745998382568\n",
      "MC_ggH_STodd_ms15_1000 \t 681.48 +- 28.37 \t 671.44 +- 28.13 \t -0.014730513095855713\n",
      "MC_ggH_STodd_ms40_1000 \t 533.15 +- 24.08 \t 529.8 +- 24.02 \t -0.006279706954956055\n",
      "MC_ggH_STodd_ms55_1000 \t 277.97 +- 17.43 \t 274.95 +- 17.34 \t -0.010855019092559814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for category in [0,1,2]:\n",
    "#     if not category == 0:continue\n",
    "    signal_yield = {}\n",
    "    signal_unc = {}\n",
    "    for k in tree.keys():\n",
    "        signal_yield[k] = []\n",
    "        signal_unc[k] = []\n",
    "    for removeJetsinHEM in [0,1]:\n",
    "        print('category {}, remove jets in HEM {}'.format(category, removeJetsinHEM))\n",
    "        weight = {}\n",
    "        nhits1 = {}\n",
    "        nhits2 = {}\n",
    "        sel_ev = {}\n",
    "        cond = {}\n",
    "        ggZH_weight = {}\n",
    "        higgsEta = {}\n",
    "        higgsPt = {}\n",
    "        EE_prefiring = {}\n",
    "        cluster_index = ''\n",
    "        addNoiseFlag = 1\n",
    "        # 0: 2 CSC; 1: 2DT; 2: csc+dt\n",
    "\n",
    "\n",
    "        for k in list(tree.keys()):\n",
    "        #     if  'data' in k:continue\n",
    "        ########### SELECTION: CLUSTERS ############\n",
    "            if 'data' in k: T = tree['data']\n",
    "            else: T = tree[k]\n",
    "\n",
    "            sel_csccluster = T.array('cscRechitCluster' + cluster_index + 'TimeSpreadWeightedAll')<20\n",
    "            sel_csccluster = np.logical_and(sel_csccluster, T.array('cscRechitCluster' + cluster_index + 'Me11Ratio')<1)\n",
    "            sel_csccluster = np.logical_and(sel_csccluster, np.logical_not(np.logical_and(T.array('cscRechitClusterMuonVetoPt') >= 30, T.array('cscRechitClusterMuonVetoGlobal'))))\n",
    "\n",
    "            if 'data' in k: \n",
    "                sel_csccluster = np.logical_and(sel_csccluster, np.logical_and(T.array('cscRechitCluster' + cluster_index + 'TimeWeighted')< 12.5, \\\n",
    "                                                                                 T.array('cscRechitCluster' + cluster_index + 'TimeWeighted') > -5))\n",
    "            else: \n",
    "                sel_csccluster = np.logical_and(sel_csccluster, np.logical_and(T.array('cscRechitCluster' + cluster_index + 'TimeWeighted')+0.66 < 12.5, \\\n",
    "                                                                                 T.array('cscRechitCluster' + cluster_index + 'TimeWeighted')+0.66 > -5))\n",
    "            if removeJetsinHEM:\n",
    "                hem_jetveto = np.logical_and(T.array('cscRechitCluster' + cluster_index + 'JetVetoEta') > -3, T.array('cscRechitCluster' + cluster_index + 'JetVetoEta') < -1.3)\n",
    "                hem_jetveto = np.logical_and(hem_jetveto, T.array('cscRechitCluster' + cluster_index + 'JetVetoPhi') < -0.87)\n",
    "                hem_jetveto = np.logical_and(hem_jetveto,T.array('cscRechitCluster' + cluster_index + 'JetVetoPhi') > -1.57)\n",
    "                hem_jetveto = np.logical_or(hem_jetveto, T.array('cscRechitCluster' + cluster_index + 'JetVetoPt') < 30)\n",
    "                sel_csccluster = np.logical_and( sel_csccluster, hem_jetveto)\n",
    "                sel_csccluster = np.logical_and(sel_csccluster, np.abs(T.array('cscRechitCluster' + cluster_index + 'MetHEM_dPhi'))<1.2)\n",
    "            else:\n",
    "                sel_csccluster = np.logical_and(sel_csccluster, T.array('cscRechitCluster' + cluster_index + 'JetVetoPt')<30)\n",
    "                sel_csccluster = np.logical_and(sel_csccluster, np.abs(T.array('cscRechitCluster' + cluster_index + 'Met_dPhi'))<1.2)\n",
    "\n",
    "\n",
    "            sel_dtcluster = np.abs(T.array('dtRechitClusterMetEENoise_dPhi')) < 10000\n",
    "            sel_dtcluster = np.logical_and(sel_dtcluster, np.logical_not(np.logical_and(T.array('dtRechitClusterMuonVetoPt') >= 10, T.array('dtRechitClusterMuonVetoLooseId'))))\n",
    "            sel_dtcluster = np.logical_and(sel_dtcluster, np.logical_not(np.logical_and(T.array('dtRechitClusterMaxStation')==1, T.array('dtRechitClusterMaxStationRatio')>0.9)))\n",
    "\n",
    "\n",
    "            cut = 5\n",
    "            station = (T.array('dtRechitClusterNSegmentStation1')>cut).astype(int)+(T.array('dtRechitClusterNSegmentStation2')>cut).astype(int)\\\n",
    "        +(T.array('dtRechitClusterNSegmentStation3')>cut).astype(int)+(T.array('dtRechitClusterNSegmentStation4')>cut).astype(int)\n",
    "\n",
    "            max_station = np.maximum(np.maximum(np.maximum(T.array('dtRechitClusterNSegmentStation1'), T.array('dtRechitClusterNSegmentStation2')), T.array('dtRechitClusterNSegmentStation3')), T.array('dtRechitClusterNSegmentStation4'))\n",
    "            min_station = np.minimum(np.minimum(np.minimum(T.array('dtRechitClusterNSegmentStation1'), T.array('dtRechitClusterNSegmentStation2')), T.array('dtRechitClusterNSegmentStation3')), T.array('dtRechitClusterNSegmentStation4'))\n",
    "\n",
    "            sel_dtcluster = np.logical_and(sel_dtcluster, np.logical_or(station<4, min_station/max_station<0.4)) #remove if both clusters are 4 stations\n",
    "            if addNoiseFlag and not 'data' in k: \n",
    "                sel_dtcluster = np.logical_and(sel_dtcluster, (T.array('dtRechitClusterSize')+T.array('dtRechitClusterNoiseHit')) >= 50)\n",
    "            else: sel_dtcluster = np.logical_and(sel_dtcluster, T.array('dtRechitClusterSize') >= 50)\n",
    "\n",
    "            # cosmic muon veto \n",
    "            sel_cosmic = np.logical_and(T.array('dtRechitClusterNOppositeSegStation1')>0, T.array('dtRechitClusterNOppositeSegStation2')>0)\n",
    "            sel_cosmic = np.logical_and(sel_cosmic, T.array('dtRechitClusterNOppositeSegStation3')>0)\n",
    "            sel_cosmic = np.logical_and(sel_cosmic, T.array('dtRechitClusterNOppositeSegStation4')>0)\n",
    "            sel_cosmic = np.logical_and(sel_cosmic, T.array('dtRechitClusterNOppositeSegStation1')+T.array('dtRechitClusterNOppositeSegStation2')+\\\n",
    "                                       T.array('dtRechitClusterNOppositeSegStation3')+T.array('dtRechitClusterNOppositeSegStation4')>=6)\n",
    "            nstation = (T.array('dtRechitClusterNSegmentStation1')>1).astype(int)+(T.array('dtRechitClusterNSegmentStation2')>1).astype(int)\\\n",
    "            +(T.array('dtRechitClusterNSegmentStation3')>1).astype(int)+(T.array('dtRechitClusterNSegmentStation4')>1).astype(int)\n",
    "\n",
    "            sel_dtcluster = np.logical_and(sel_dtcluster, np.logical_not(np.logical_and(nstation>=3, sel_cosmic)))\n",
    "\n",
    "            if removeJetsinHEM:\n",
    "                hem_jetveto = np.logical_and(T.array('dtRechitCluster' + cluster_index + 'JetVetoEta') > -3, T.array('dtRechitCluster' + cluster_index + 'JetVetoEta') < -1.3)\n",
    "                hem_jetveto = np.logical_and(hem_jetveto, T.array('dtRechitCluster' + cluster_index + 'JetVetoPhi') < -0.87)\n",
    "                hem_jetveto = np.logical_and(hem_jetveto,T.array('dtRechitCluster' + cluster_index + 'JetVetoPhi') > -1.57)\n",
    "                hem_jetveto = np.logical_or(hem_jetveto, T.array('dtRechitCluster' + cluster_index + 'JetVetoPt') < 50)\n",
    "                sel_dtcluster = np.logical_and( sel_dtcluster, hem_jetveto)\n",
    "                sel_dtcluster = np.logical_and(sel_dtcluster, np.abs(T.array('dtRechitCluster' + cluster_index + 'MetHEM_dPhi'))<1)\n",
    "\n",
    "            else:\n",
    "                sel_dtcluster = np.logical_and(sel_dtcluster, np.abs(T.array('dtRechitClusterJetVetoPt')) < 50)\n",
    "                sel_dtcluster = np.logical_and(sel_dtcluster, np.abs(T.array('dtRechitCluster' + cluster_index + 'Met_dPhi'))<1)\n",
    "        ########### SELECTION: JETS ############\n",
    "\n",
    "            sel_jet = np.logical_and(T.array('jetPt') > 30, np.abs(T.array('jetEta')) < 2.4 )\n",
    "            sel_jet = np.logical_and(T.array('jetTightPassId'), sel_jet)\n",
    "\n",
    "\n",
    "\n",
    "        ########### SELECTION: NOISE IN DT ############\n",
    "\n",
    "            spike = np.logical_and( T.array('nDTRechitsSector')[:,0,0,7]>50,  T.array('nDTRechitsSector')[:,0,0,7]+T.array('nDTRechitsSector')[:,0,0,8]+T.array('nDTRechitsSector')[:,0,0,9]>120)\n",
    "            spike = np.logical_and(spike, T.array('nDTRechitsSector')[:,0,0,8]>25)\n",
    "            spike = np.logical_and(spike, T.array('nDTRechitsSector')[:,0,0,9]>10)\n",
    "\n",
    "\n",
    "\n",
    "        ########### SELECTION: EVENTS ############\n",
    "\n",
    "            sel_ev[k] = T.array('METNoMuTrigger')\n",
    "#             if removeJetsinHEM:sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('metHEM') >= 200)\n",
    "#             else:sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('met') >= 200)\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('met') >= 200)\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k] , sel_jet.sum()>=1)\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k], (T.array('nDtRings')+T.array('nCscRings'))<10)\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k],T.array('Flag2_all'))\n",
    "            sel_ev[k] = np.logical_and(sel_ev[k] , np.logical_not(spike))\n",
    "\n",
    "        ########### BRANCHES ############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if category == 0:\n",
    "                sel_ev[k]  = np.logical_and(sel_ev[k],sel_csccluster.sum()== 2)\n",
    "                sel_ev[k]  = np.logical_and(sel_ev[k],sel_dtcluster.sum()== 0)\n",
    "                cond[k] = deltaR(T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_csccluster][sel_ev[k]][:,0], T.array('cscRechitCluster' + cluster_index + 'Phi')[sel_csccluster][sel_ev[k]][:,0],\\\n",
    "                                T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_csccluster][sel_ev[k]][:,1], T.array('cscRechitCluster' + cluster_index + 'Phi')[sel_csccluster][sel_ev[k]][:,1])<2\n",
    "\n",
    "\n",
    "                nhits1[k] =  T.array('cscRechitCluster' + cluster_index + 'Size')[sel_csccluster][sel_ev[k]][cond[k]][:,0]\n",
    "                nhits2[k] =  T.array('cscRechitCluster' + cluster_index + 'Size')[sel_csccluster][sel_ev[k]][cond[k]][:,1]\n",
    "        #         deltaRCluster[k] = deltaR(T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_csccluster][sel_ev[k]][:,0], T.array('cscRechitCluster' + cluster_index + 'Phi')[sel_csccluster][sel_ev[k]][:,0],\\\n",
    "        #                         T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_csccluster][sel_ev[k]][:,1], T.array('cscRechitCluster' + cluster_index + 'Phi')[sel_csccluster][sel_ev[k]][:,1])\n",
    "            elif category == 1:\n",
    "                sel_ev[k]  = np.logical_and(sel_ev[k],sel_dtcluster.sum()== 2)\n",
    "                sel_ev[k]  = np.logical_and(sel_ev[k],sel_csccluster.sum()== 0)\n",
    "                cond[k] = np.abs(T.array('dtRechitCluster' + cluster_index + 'Eta')[sel_dtcluster][sel_ev[k]][:,0]-\\\n",
    "                                                            T.array('dtRechitCluster' + cluster_index + 'Eta')[sel_dtcluster][sel_ev[k]][:,1])>=0\n",
    "                if addNoiseFlag and not 'data' in k:\n",
    "                    nhits1[k] =  (T.array('dtRechitClusterNoiseHit')+T.array('dtRechitClusterSize'))[sel_dtcluster][sel_ev[k]][:,0]\n",
    "                    nhits2[k] =  (T.array('dtRechitClusterNoiseHit')+T.array('dtRechitClusterSize'))[sel_dtcluster][sel_ev[k]][:,1]\n",
    "                else:\n",
    "                    nhits1[k] =  T.array('dtRechitClusterSize')[sel_dtcluster][sel_ev[k]][:,0]\n",
    "                    nhits2[k] =  T.array('dtRechitClusterSize')[sel_dtcluster][sel_ev[k]][:,1]\n",
    "            elif category == 2:\n",
    "                sel_ev[k]  = np.logical_and(sel_ev[k],sel_csccluster.sum() == 1)\n",
    "                sel_ev[k]  = np.logical_and(sel_ev[k],sel_dtcluster.sum() == 1)\n",
    "\n",
    "        #         cond[k] =  np.abs(T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_csccluster][sel_ev[k]][:,0]-\\\n",
    "        #                                                     T.array('dtRechitCluster' + cluster_index + 'Eta')[sel_dtcluster][sel_ev[k]][:,0])<2.0\n",
    "\n",
    "                cond[k] = deltaR(T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_csccluster][sel_ev[k]][:,0], T.array('cscRechitCluster' + cluster_index + 'Phi')[sel_csccluster][sel_ev[k]][:,0],\\\n",
    "                                T.array('dtRechitCluster' + cluster_index + 'Eta')[sel_dtcluster][sel_ev[k]][:,0], T.array('dtRechitCluster' + cluster_index + 'Phi')[sel_dtcluster][sel_ev[k]][:,0])<2.5\n",
    "                if addNoiseFlag and not 'data' in k:\n",
    "                    nhits1[k] =  (T.array('dtRechitClusterNoiseHit')+T.array('dtRechitClusterSize'))[sel_dtcluster][sel_ev[k]][cond[k]][:,0]\n",
    "                else:\n",
    "                    nhits1[k] =  T.array('dtRechitClusterSize')[sel_dtcluster][sel_ev[k]][cond[k]][:,0]\n",
    "                nhits2[k] =  T.array('cscRechitCluster' + cluster_index + 'Size')[sel_csccluster][sel_ev[k]][cond[k]][:,0]\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                assert(False)\n",
    "\n",
    "\n",
    "            higgsPt[k] = T.array('gHiggsPt')[sel_ev[k]][cond[k]]\n",
    "            higgsEta[k] = T.array('gHiggsEta')[sel_ev[k]][cond[k]]\n",
    "\n",
    "            ggZH_weight[k]=h_reweight.values[np.argmax(h_reweight.edges[0]>higgsPt[k][:,None],axis=1)-1, np.argmax(h_reweight.edges[1]>np.abs(higgsEta[k])[:,None],axis=1)-1]\n",
    "\n",
    "\n",
    "            if 'ggH' in k: weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('higgsPtWeight')*T.array('metSF'))[sel_ev[k]][cond[k]]\n",
    "            else:weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('metSF'))[sel_ev[k]][cond[k]]\n",
    "            if 'ggZH' in k: weight[k] *= ggZH_weight[k]\n",
    "#             print(k,'\\t', np.sum(weight[k]))\n",
    "            signal_yield[k].append(np.sum(weight[k]))\n",
    "            signal_unc[k].append(np.sum(weight[k]**2)**0.5)\n",
    "\n",
    "    for k in signal_yield.keys():\n",
    "        print(k, '\\t', round(signal_yield[k][0],2), '+-',round(signal_unc[k][0],2),'\\t',round(signal_yield[k][1],2), '+-',round(signal_unc[k][1],2), '\\t',signal_yield[k][1]/ signal_yield[k][0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
