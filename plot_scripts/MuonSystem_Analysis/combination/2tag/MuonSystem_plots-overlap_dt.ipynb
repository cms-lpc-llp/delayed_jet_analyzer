{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "# check overlap with EXO-21-008 signal\n",
    "\n",
    "import ROOT as rt\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import awkward\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/af/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "sys.path.append('/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/python/')\n",
    "from helper import  make_datacard_2sig, make_datacard_2tag, weight_calc\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "from helper_functions import deltaR\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC_ggH_15_100 6984998.0\n",
      "MC_VBFH_15_100 2425654.0\n",
      "MC_ZH_15_100 199500.0\n",
      "MC_WH_15_100 297997.0\n",
      "MC_ttH_H_15_100 102500.0\n",
      "MC_ggZH_15_100 199500.0\n",
      "MC_ggH_15_1000 6924000.0\n",
      "MC_VBFH_15_1000 2350380.0\n",
      "MC_ZH_15_1000 149900.0\n",
      "MC_WH_15_1000 299500.0\n",
      "MC_ttH_H_15_1000 130000.0\n",
      "MC_ggZH_15_1000 149900.0\n",
      "MC_ggH_15_10000 7157000.0\n",
      "MC_VBFH_15_10000 856280.0\n",
      "MC_ZH_15_10000 149297.0\n",
      "MC_WH_15_10000 377298.0\n",
      "MC_ttH_H_15_10000 149400.0\n",
      "MC_ggZH_15_10000 149297.0\n",
      "MC_ggH_15_100000 7075998.0\n",
      "MC_VBFH_15_100000 892602.0\n",
      "MC_ZH_15_100000 768698.0\n",
      "MC_WH_15_100000 1210293.0\n",
      "MC_ttH_H_15_100000 178900.0\n",
      "MC_ggZH_15_100000 768698.0\n",
      "MC_ggH_40_100 6931381.0\n",
      "MC_VBFH_40_100 813041.0\n",
      "MC_ZH_40_100 1047369.0\n",
      "MC_WH_40_100 2173016.0\n",
      "MC_ttH_H_40_100 50000.0\n",
      "MC_ggZH_40_100 1047369.0\n",
      "MC_ggH_40_1000 6916000.0\n",
      "MC_VBFH_40_1000 832573.0\n",
      "MC_ZH_40_1000 149490.0\n",
      "MC_WH_40_1000 298386.0\n",
      "MC_ttH_H_40_1000 149300.0\n",
      "MC_ggZH_40_1000 149490.0\n",
      "MC_ggH_40_10000 7056998.0\n",
      "MC_VBFH_40_10000 825334.0\n",
      "MC_ZH_40_10000 148492.0\n",
      "MC_WH_40_10000 248086.0\n",
      "MC_ttH_H_40_10000 149100.0\n",
      "MC_ggZH_40_10000 148492.0\n",
      "MC_ggH_40_100000 7286483.0\n",
      "MC_VBFH_40_100000 836076.0\n",
      "MC_ZH_40_100000 547884.0\n",
      "MC_WH_40_100000 1207647.0\n",
      "MC_ttH_H_40_100000 549300.0\n",
      "MC_ggZH_40_100000 547884.0\n",
      "MC_ggH_55_100 6890999.0\n",
      "MC_VBFH_55_100 825669.0\n",
      "MC_ZH_55_100 49897.0\n",
      "MC_WH_55_100 99191.0\n",
      "MC_ttH_H_55_100 50000.0\n",
      "MC_ggZH_55_100 49897.0\n",
      "MC_ggH_55_1000 7030000.0\n",
      "MC_VBFH_55_1000 833817.0\n",
      "MC_ZH_55_1000 226083.0\n",
      "MC_WH_55_1000 199681.0\n",
      "MC_ttH_H_55_1000 149600.0\n",
      "MC_ggZH_55_1000 226083.0\n",
      "MC_ggH_55_10000 7017227.0\n",
      "MC_VBFH_55_10000 865747.0\n",
      "MC_ZH_55_10000 136688.0\n",
      "MC_WH_55_10000 296279.0\n",
      "MC_ttH_H_55_10000 149900.0\n",
      "MC_ggZH_55_10000 136688.0\n",
      "MC_ggH_55_100000 7053000.0\n",
      "MC_VBFH_55_100000 868009.0\n",
      "MC_ZH_55_100000 548556.0\n",
      "MC_WH_55_100000 1098305.0\n",
      "MC_ttH_H_55_100000 549200.0\n",
      "MC_ggZH_55_100000 548556.0\n"
     ]
    }
   ],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "mass = [15, 40, 55]\n",
    "\n",
    "# prod = ['ggH', 'VBFH_H','ZH', 'WH', 'ttH_H','ggZH']\n",
    "# decay = 'dddd'\n",
    "\n",
    "\n",
    "prod = ['ggH','VBFH','ZH', 'WH', 'ttH_H','ggZH']\n",
    "prod = ['ggH']\n",
    "decay = '4Tau'\n",
    "\n",
    "prod = ['ggH','VBFH','ZH', 'WH', 'ttH_H','ggZH']\n",
    "decay = 'bbbb'\n",
    "\n",
    "\n",
    "mass = [15, 40, 55]\n",
    "if not decay == 'bbbb': mass = [7, 15, 40, 55]\n",
    "\n",
    "OLD_CTAU = np.array([100, 1000, 10000, 100000])#in mm\n",
    "\n",
    "ntupler_version = 'V1p17/'\n",
    "\n",
    "# data_path = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/Data2018/v5/v100/normalized/' #what is used in final version of EXO-20-015\n",
    "data_path = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17//Data2018//v5/v138//normalized/'\n",
    "fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p17_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "mc_path = {}\n",
    "\n",
    "analyzer_version = 'v1/v138/'\n",
    "mc_path['ggH'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_all/'+analyzer_version+'/normalized/'\n",
    "mc_path['VBFH'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_all/'+analyzer_version+'/normalized/'\n",
    "analyzer_version = 'v2/v138/'\n",
    "mc_path['ZH'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['WH'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['WminusH'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['WplusH'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['ttH_H'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['VBFH_H'] = '/storage/af/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['ggZH'] = mc_path['ZH']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "        for p in prod:\n",
    "            if p == 'others':continue\n",
    "            if p == 'VBFH' and decay == 'bbbb':\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "                fpath[key] = mc_path[p]+p+'_HToSSTo4b_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_137000pb_weighted.root'\n",
    "            elif p == 'ggH' or p == 'VBFH':\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "                fpath[key] = mc_path[p]+p+'_HToSSTo'+decay+'_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_137000pb_weighted.root'\n",
    "            elif p == 'VBFH_H':\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)  \n",
    "                fpath[key] = mc_path[p]+'VBFHToSS_STodd_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "            else:\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "                if decay == 'bbbb':fpath[key] = mc_path[p] + p+'ToSS_SToBB_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                if decay == 'dddd':fpath[key] = mc_path[p] + p+'ToSS_STodd_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                if decay == '4Tau':fpath[key] = mc_path[p] + p+'ToSS_SToTauTau_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                if p == 'ggZH':\n",
    "                    if decay == 'bbbb':fpath[key] = mc_path[p] + 'ZHToSS_SToBB_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                    if decay == 'dddd':fpath[key] = mc_path[p] + 'ZHToSS_STodd_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                    if decay == '4Tau':fpath[key] = mc_path[p] + 'ZHToSS_SToTauTau_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "\n",
    "\n",
    "# fpath['hnl']= '/storage/af/user/christiw/HNL_electronType_ms5p0_plVe2_1e-5/HeavyNeutralLepton_Tree.root'                        \n",
    "NEvents = {}\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    root_dir = uproot.open(v) \n",
    "    if not root_dir: \n",
    "        print(k, \"zombie\")\n",
    "        continue\n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]\n",
    "    \n",
    "    w = tree[k][\"weight\"].array()\n",
    "    if not 'data' in k: \n",
    "        print(k, root_dir['NEvents']._fEntries)\n",
    "        \n",
    "\n",
    "\n",
    "root_dir = uproot.open('/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/HiggsPtWeights/ZHToggZH_HiggsPtReweight.root') \n",
    "h_reweight = root_dir['higgsPthiggsEta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "JET_PT_CUT = 10.0\n",
    "MUON_PT_CUT = 20.0\n",
    "N_RECHIT_CUT = 90\n",
    "jetPt_cut = 50\n",
    "tightid = False\n",
    "ring_cut = 50\n",
    "cut_based = True\n",
    "cut_based_version = 'v4'\n",
    "\n",
    "intime = True\n",
    "DPHI_CUT = 1\n",
    "weight = {}\n",
    "\n",
    "nCsc_JetMuonVetoCluster0p4_Me1112Veto = {}\n",
    "dphiMet_cluster = {}\n",
    "\n",
    "cscRechitClusterEta = {}\n",
    "cscRechitClusterNStation10  = {}\n",
    "cscRechitClusterAvgStation10 = {}\n",
    "\n",
    "sel_ev = {}\n",
    "bdt_sel = {}\n",
    "sel_csc = {}\n",
    "sel_dt = {}\n",
    "\n",
    "ggZH_weight = {}\n",
    "higgsEta = {}\n",
    "higgsPt = {}\n",
    "\n",
    "\n",
    "cluster_index = ''\n",
    "\n",
    "NStation_weight = {}\n",
    "AvgStation_weight = {}\n",
    "Eta_weight = {}\n",
    "\n",
    "sel_csccluster = {}\n",
    "sel_dtcluster = {}\n",
    "dt_dt = {}\n",
    "csc_csc = {}\n",
    "csc_dt = {}\n",
    "nDtWheels25 = {}\n",
    "nDtStations25 = {}\n",
    "two_tag = {}\n",
    "dR = {}\n",
    "for k in list(tree.keys()):\n",
    "    if 'data' in k:continue\n",
    "#     if not k == 'data_intime_sr':continue\n",
    "########### SELECTION: CLUSTERS ############\n",
    "    if 'data' in k: T = tree['data']\n",
    "    else: T = tree[k]\n",
    "\n",
    "#     if '15' in k or '40' in k:continue\n",
    "#     if not k == 'old':continue\n",
    "########### SELECTION: CLUSTERS ############\n",
    "\n",
    "\n",
    "    sel_rechitcluster = np.logical_and( T.array('dtRechitClusterMuonVetoPt') < 10, T.array('dtRechitClusterJetVetoPt') < 20)\n",
    "     \n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('dtRechitCluster_match_RPChits_dPhi0p5') > 0)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('dtRechitCluster_match_MB1hits_cosmics_minus') <= 8)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('dtRechitCluster_match_MB1hits_cosmics_plus') <= 8)  \n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('dtRechitCluster_match_MB1hits_0p5') <= 1)\n",
    "\n",
    "\n",
    "########### SELECTION: JETS ############\n",
    "    \n",
    "\n",
    "    sel_jet = np.logical_and(T.array('jetPt') > 30, np.abs(T.array('jetEta')) < 2.4 )\n",
    "    sel_jet = np.logical_and(T.array('jetTightPassId'), sel_jet)\n",
    "########### SELECTION: EVENTS ############\n",
    "    hlt = T['HLTDecision'].array()\n",
    "    sel_ev[k] = T.array('metEENoise') > 200\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] , sel_jet.sum()>=1)\n",
    "\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k],T.array('nDtStations25')<3)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k],T.array('nDtWheels25')<3)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k],T.array('Flag2_all'))\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k],np.abs(T.array('jetMet_dPhiMin'))>0.6)\n",
    "\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k],sel_rechitcluster.sum() >= 1)\n",
    "\n",
    "\n",
    "\n",
    "########### BRANCHES ############\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    higgsPt[k] = T.array('gHiggsPt')[sel_ev[k]]\n",
    "    higgsEta[k] = T.array('gHiggsEta')[sel_ev[k]]\n",
    "    ggZH_weight[k]=h_reweight.values[np.argmax(h_reweight.edges[0]>higgsPt[k][:,None],axis=1)-1, np.argmax(h_reweight.edges[1]>np.abs(higgsEta[k])[:,None],axis=1)-1]\n",
    "\n",
    "\n",
    "    if 'ggH' in k: weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('higgsPtWeight')*T.array('metSF'))[sel_ev[k]]\n",
    "    else:weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('metSF'))[sel_ev[k]]\n",
    "    if 'ggZH' in k: weight[k] *= ggZH_weight[k]\n",
    "        \n",
    "    ###################\n",
    "    # 2 tag selections\n",
    "    ###################\n",
    "    sel_csccluster[k] = np.logical_and(T.array('cscRechitCluster' + cluster_index + 'TimeTotal') < 12.5,  T.array('cscRechitCluster' + cluster_index + 'TimeTotal') > -5)\n",
    "    sel_csccluster[k] = np.logical_and(sel_csccluster[k], np.abs(T.array('cscRechitCluster' + cluster_index + 'MetEENoise_dPhi'))<1.2)\n",
    "    sel_csccluster[k] = np.logical_and(sel_csccluster[k], T.array('cscRechitCluster' + cluster_index + 'JetVetoPt')<30)\n",
    "    sel_csccluster[k] = np.logical_and(sel_csccluster[k],  T.array('cscRechitCluster' + cluster_index + 'TimeSpread') <= 20)\n",
    "    sel_csccluster[k] = np.logical_and(sel_csccluster[k],  T.array('cscRechitCluster' + cluster_index + 'Me11Ratio') <1)\n",
    "\n",
    "\n",
    "    sel_csccluster[k] = sel_csccluster[k][sel_ev[k]]\n",
    "    sel_dtcluster[k] = T.array('dtRechitCluster_match_RPChits_dPhi0p5')>0\n",
    "    sel_dtcluster[k] = np.logical_and(sel_dtcluster[k], np.abs(T.array('dtRechitClusterMetEENoise_dPhi')) < 1)\n",
    "    sel_dtcluster[k] = np.logical_and(sel_dtcluster[k], np.abs(T.array('dtRechitClusterJetVetoPt')) < 50)\n",
    "    sel_dtcluster[k] = np.logical_and(sel_dtcluster[k], np.logical_not(np.logical_and(T.array('dtRechitClusterMaxStation')==1, T.array('dtRechitClusterMaxStationRatio')>0.9)))\n",
    "    sel_dtcluster[k] = sel_dtcluster[k][sel_ev[k]]\n",
    "\n",
    "    #########################\n",
    "    # overlap calculation\n",
    "    #########################\n",
    "\n",
    "    csc_csc[k] = np.logical_and(sel_csccluster[k].sum() == 2, sel_dtcluster[k].sum()==0)\n",
    "    dt_dt[k] = np.logical_and(sel_csccluster[k].sum() == 0, sel_dtcluster[k].sum()==2)\n",
    "    csc_dt[k] = np.logical_and(sel_csccluster[k].sum() == 1, sel_dtcluster[k].sum()==1)\n",
    "\n",
    "    dR[k] = deltaR(T.array('cscRechitClusterEta')[sel_ev[k]][sel_csccluster[k]][csc_dt[k]][:,0], \\\n",
    "               T.array('cscRechitClusterPhi')[sel_ev[k]][sel_csccluster[k]][csc_dt[k]][:,0],\\\n",
    "               T.array('dtRechitClusterEta')[sel_ev[k]][sel_dtcluster[k]][csc_dt[k]][:,0],\\\n",
    "               T.array('dtRechitClusterPhi')[sel_ev[k]][sel_dtcluster[k]][csc_dt[k]][:,0])\n",
    "\n",
    "    nDtStations25[k] = T.array('nDtStations25')[sel_ev[k]]\n",
    "    nDtWheels25[k]= T.array('nDtWheels25')[sel_ev[k]]\n",
    "    two_tag[k] = sel_csccluster[k].sum() + sel_dtcluster[k].sum()>=2\n",
    "\n",
    "#     print(k, '\\t', np.count_nonzero(csc_csc[k])/len(csc_csc[k]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1\n",
      "149 149 149\n",
      "[] [] [] []\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "k = 'data_intime_sr'\n",
    "print(np.count_nonzero(csc_csc[k]), np.count_nonzero(dt_dt[k]), np.count_nonzero(csc_dt[k]))\n",
    "print(len(csc_csc[k]), len(dt_dt[k]), len(csc_dt[k]))\n",
    "cond = sel_csccluster[k].sum()+sel_dtcluster[k].sum()>2\n",
    "\n",
    "print(sel_csccluster[k].sum()[cond], sel_dtcluster[k].sum()[cond], nDtStations25[k][cond], nDtWheels25[k][cond])\n",
    "print(np.count_nonzero(bdt_sel[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 GeV, c$\\tau$ 100 mm &  0.0\\% &  0.0\\% &  0.26\\% &  0.26\\% \\\\\n",
      "15 GeV, c$\\tau$ 1000 mm &  0.0\\% &  4.23\\% &  5.37\\% &  9.6\\% \\\\\n",
      "15 GeV, c$\\tau$ 10000 mm &  0.0\\% &  0.38\\% &  0.64\\% &  1.02\\% \\\\\n",
      "15 GeV, c$\\tau$ 100000 mm &  0.0\\% &  0.0\\% &  0.13\\% &  0.13\\% \\\\\n",
      "40 GeV, c$\\tau$ 100 mm &  0.0\\% &  0.0\\% &  0.0\\% &  0.0\\% \\\\\n",
      "40 GeV, c$\\tau$ 1000 mm &  0.0\\% &  4.68\\% &  7.06\\% &  11.74\\% \\\\\n",
      "40 GeV, c$\\tau$ 10000 mm &  0.0\\% &  1.54\\% &  1.66\\% &  3.21\\% \\\\\n",
      "40 GeV, c$\\tau$ 100000 mm &  0.0\\% &  0.08\\% &  0.13\\% &  0.21\\% \\\\\n",
      "55 GeV, c$\\tau$ 100 mm &  nan\\% &  nan\\% &  nan\\% &  nan\\% \\\\\n",
      "55 GeV, c$\\tau$ 1000 mm &  0.0\\% &  0.41\\% &  3.83\\% &  4.25\\% \\\\\n",
      "55 GeV, c$\\tau$ 10000 mm &  0.0\\% &  0.43\\% &  1.12\\% &  1.54\\% \\\\\n",
      "55 GeV, c$\\tau$ 100000 mm &  0.0\\% &  0.04\\% &  0.36\\% &  0.4\\% \\\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "        dt_analysis = 0\n",
    "        csc_csc_temp = 0\n",
    "        csc_dt_temp = 0\n",
    "        dt_dt_temp = 0\n",
    "        gt2tag = 0\n",
    "        for p in prod:\n",
    "            k = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "            cond = sel_csccluster[k].sum()+sel_dtcluster[k].sum()>2\n",
    "            dt_analysis += np.sum(weight[k])\n",
    "            csc_csc_temp += np.sum(weight[k][ csc_csc[k]])\n",
    "            csc_dt_temp += np.sum(weight[k][csc_dt[k]])\n",
    "            dt_dt_temp += np.sum(weight[k][dt_dt[k]])\n",
    "            gt2tag += np.sum(weight[k][cond])\n",
    " \n",
    "#         print(str(m)+'_'+str(ct), '\\t',csc_csc_temp/dt_analysis, \\\n",
    "#               '\\t',dt_dt_temp/dt_analysis, \\\n",
    "#               '\\t',csc_dt_temp/dt_analysis, \\\n",
    "#               '\\t',gt2tag/dt_analysis)\n",
    "        print(str(m)+' GeV, c$\\\\tau$ '+str(ct)+' mm', '& ',str(round(csc_csc_temp/dt_analysis*100,2))+'\\\\%', \\\n",
    "              '& ',str(round(dt_dt_temp/dt_analysis*100,2))+'\\\\%', \\\n",
    "              '& ',str(round(csc_dt_temp/dt_analysis*100,2))+'\\\\%', \\\n",
    "              '& ',str(round((csc_csc_temp+dt_dt_temp+csc_dt_temp)/dt_analysis*100,2))+'\\\\%', '\\\\\\\\')\n",
    "\n",
    "\n",
    "\n",
    "        #     print(len(csc_csc[k]), len(dt_dt[k]), len(csc_dt[k]))\n",
    "#     print(np.count_nonzero(bdt_sel[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal yield summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 \t 1.9\t6.3\t1.5\t0.1\n",
      "40 \t 0.0\t5.3\t4.4\t0.7\n",
      "55 \t 0.0\t2.2\t5.9\t0.9\n"
     ]
    }
   ],
   "source": [
    "ctaus = [ '100', '1000','10000','100000' ]\n",
    "\n",
    "\n",
    "BR = 0.01\n",
    "N_RECHIT_CUT = 130\n",
    "DPHI_CUT = 0.75\n",
    "corrections = 0.8953452999999999\n",
    "\n",
    "# corrections = 0.902012765\n",
    "var = dphiMet_cluster\n",
    "# DPHI_CUT = 0.6      \n",
    "# var = jetMet_dPhiMin30\n",
    "for N_RECHIT_CUT in np.arange(60,220,10):\n",
    "    if not N_RECHIT_CUT==130:continue\n",
    "    total_sig = 0\n",
    "    for m in mass:\n",
    "#         if not m == 55:continue\n",
    "        signal_rate = []\n",
    "        unc_rate = []\n",
    "        signal_unc = []\n",
    "        for ct in ctaus:   \n",
    "#             if not ct == '1000':continue\n",
    "            signal = 0\n",
    "            sig_unc = 0\n",
    "            shape_unc_temp = 0\n",
    "            ctf = int(ct)\n",
    "            if ctf < OLD_CTAU[0]:\n",
    "                old_ctau_temp = np.array([OLD_CTAU[0]])\n",
    "            else:\n",
    "                for j, ct0 in enumerate(OLD_CTAU):\n",
    "                    if ct0 == ctf: \n",
    "                        old_ctau_temp = np.array([int(ctf)])\n",
    "                        break\n",
    "\n",
    "                    elif ct0 > ctf:\n",
    "                        old_ctau_temp = np.array([OLD_CTAU[j-1], OLD_CTAU[j]])\n",
    "                        old_ctau_temp = np.array([OLD_CTAU[j]])\n",
    "                        break\n",
    "                    if j == len(OLD_CTAU)-1: \n",
    "                        old_ctau_temp = np.array([OLD_CTAU[j]])\n",
    "\n",
    "            weight_sum = 0\n",
    "            weight_len = 0\n",
    "            for j,ct0 in enumerate(old_ctau_temp):\n",
    "                prods = ['ggH', 'VBFH','WH','ZH','ttH_H','ggZH']\n",
    "                prods = ['VBFH',]\n",
    "                #VBFH and WH is a bit off\n",
    "                for p in prods:\n",
    "                    \n",
    "                    k = 'MC_'+p+'_'+str(m)+'_'+str(ct0)+''\n",
    "                    \n",
    "\n",
    "                    T = tree[k]\n",
    "                    if np.count_nonzero(sel_ev[k]) == 0: continue\n",
    "                    gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                    if len(gLLP_ctau) == 0: continue\n",
    "\n",
    "                    w = weight[k]*AvgStation_weight[k][bdt_sel[k]]*NStation_weight[k][bdt_sel[k]]\n",
    "                    w = weight[k]\n",
    "                    # higgs pt, signal uncertainty weight\n",
    "                    cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, np.abs(var[k])<DPHI_CUT)#bin D\n",
    "#                     cond = np.logical_and(cond, np.logical_not(two_tag[k]))\n",
    "                    signal += np.sum(w[cond])\n",
    "#                     signal += np.count_nonzero(cond)\n",
    "#                     print(np.mean(w[cond]))\n",
    "                    sig_unc +=np.sum(w[cond]*w[cond])\n",
    "#                     shape_unc_temp = (shape_unc_temp**2+np.sum(w[cond]*shape_unc[cond])**2)**0.5\n",
    "\n",
    "\n",
    "            signal_rate.append(signal)\n",
    "            signal_unc.append(sig_unc**0.5)\n",
    "            unc_rate.append(shape_unc_temp)\n",
    "        signal_rate = np.array(signal_rate)\n",
    "        unc_rate = np.array(unc_rate)\n",
    "        signal_unc = np.array(signal_unc)\n",
    "#         print(N_RECHIT_CUT, '\\t', signal_rate[0]*BR)\n",
    "#         print(m,'GeV &', ' & '.join(map(str, [round(num,1) for num in signal_rate*BR*corrections])),'\\\\\\\\')\n",
    "#         print(m,'GeV &', ' & '.join(map(str, [round(num,1) for num in signal_rate*limit[m]])),'\\\\\\\\')\n",
    "\n",
    "#         print(m, '\\t', '\\t'.join(map(str, [round(num,2) for num in signal_unc*BR])))\n",
    "        print(m, '\\t', '\\t'.join(map(str, [round(num,1) for num in signal_rate*BR*corrections])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetVeto = {}\n",
    "muonVeto = {}\n",
    "rechitVeto = {}\n",
    "cut_based_eff_unc = {}\n",
    "clusterEff_unc = {}\n",
    "higgsPtWeight = {}\n",
    "JES = {}\n",
    "pileup = {}\n",
    "# ctau_reweight = {}\n",
    "mc_stats = {}\n",
    "scaling = {}\n",
    "lumi = {}\n",
    "time_spread = {}\n",
    "time = {}\n",
    "theory = {}\n",
    "pdf = {}\n",
    "readout = {}\n",
    "ggH_higgsPt , VBFH_higgsPt , WH_higgsPt , ZH_higgsPt , ttH_higgsPt , ggZH_higgsPt =({} for i in range(6)) \n",
    "ggH_qcdScale , VBFH_qcdScale , WH_qcdScale , ZH_qcdScale , ttH_qcdScale , ggZH_qcdScale =({} for i in range(6)) \n",
    "ggH_pdf , VBFH_pdf , WH_pdf , ZH_pdf , ttH_pdf , ggZH_pdf =({} for i in range(6)) \n",
    "Nrechit_weight_file = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/Uncertainties/Nrechit_weight.txt'\n",
    "\n",
    "cut_based_unc = [0.0921, 0.0852] # muon Eta reweighted\n",
    "clustering_unc = [0.1506, 0.1047]\n",
    "\n",
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "        for p in prod:\n",
    "            if p == 'others':k = 'MC_ggH_'+str(m)+'_'+str(ct)   \n",
    "            else:k = 'MC_'+p+'_'+str(m)+'_'+str(ct)         \n",
    "            if p == 'others': key = 'MC_others_'+str(m)+'_'+str(ct)   \n",
    "            else: key = k\n",
    "\n",
    "\n",
    "            lumi[key] = [0.018]*4\n",
    "            jetVeto[key] = [0.00068]*4\n",
    "            muonVeto[key] = [0.045]*4\n",
    "            rechitVeto[key] = [0.001]*4\n",
    "            time[key] = [0.009]*4\n",
    "            time_spread[key] = [0.028]*4\n",
    "            clusterEff_unc[key]  = [0.035] * 4 #shifting Nrechit cut from 130 to 135\n",
    "            cut_based_eff_unc[key]=[0.051]*4 #muon eta reweighted\n",
    "            readout[key]=[0.01]*4 \n",
    "            JES[key] = [0.084,0.083,0.042,0.041]\n",
    "            pileup[key] = [0.008, 0.0110, 0.0110, 0.0110]\n",
    "            \n",
    "\n",
    "            ggH_higgsPt[key], VBFH_higgsPt[key], WH_higgsPt[key] , ZH_higgsPt[key] , ttH_higgsPt[key] , ggZH_higgsPt[key] = ([0.0]*8,)*6\n",
    "            ggH_qcdScale[key], VBFH_qcdScale[key], WH_qcdScale[key] , ZH_qcdScale[key] , ttH_qcdScale[key] , ggZH_qcdScale[key] = ([0.0]*8,)*6\n",
    "            ggH_pdf[key] , VBFH_pdf[key] , WH_pdf[key] , ZH_pdf[key] , ttH_pdf[key] , ggZH_pdf[key] = ([0.0]*4,)*6\n",
    "            if 'ggH' in key: \n",
    "                ggH_higgsPt[key] = [0.205, 0.205,0.207,0.208, 0.133,0.133,0.134,0.134] #down*4/up*4\n",
    "                ggH_qcdScale[key] = [0.067]*4+[0.046]*4 #down/up\n",
    "                ggH_pdf[key] = [0.032]*4\n",
    "\n",
    "            elif 'VBFH' in key: \n",
    "                VBFH_higgsPt[key] = [0.046, 0.159, 0.007, 0.006, 0.022, 0.032, 0.012, 0.010] #down/up\n",
    "                VBFH_qcdScale[key] = [0.003]*4+[0.004]*4 #down/up\n",
    "                VBFH_pdf[key] = [0.021]*4\n",
    "            elif 'ggZH' in key:\n",
    "                ggZH_higgsPt[key] = [0.194, 0.198, 0.208, 0.208, 0.120, 0.123, 0.134, 0.133] #down/up,ggZH\n",
    "                ggZH_qcdScale[key] = [0.251]*4+[0.189]*4 #down/up\n",
    "                ggZH_pdf[key] = [0.024]*4\n",
    "#                 scaling[key] = [0.2]*4\n",
    "            elif 'ZH' in key: \n",
    "                ZH_higgsPt[key] = [0.125, 0.057, 0.01, 0.017, 0.033,0.018, 0.006, 0.006] #down/up\n",
    "                ZH_qcdScale[key] = [0.006]*4+[0.005]*4 #down/up\n",
    "                ZH_pdf[key] = [0.019]*4\n",
    "            elif 'WH' in key: \n",
    "                WH_higgsPt[key] = [0.071,0.040, 0.003, 0.054, 0.026, 0.024, 0.004, 0.018] #down/up\n",
    "                WH_qcdScale[key] = [0.007]*4+[0.005]*4 #down/up\n",
    "                WH_pdf[key] = [0.019]*4\n",
    "            elif 'ttH' in key: \n",
    "                ttH_higgsPt[key] = [0.012, 0.148, 0.051, 0.028, 0.007, 0.066, 0.016, 0.010] #down/up\n",
    "                ttH_qcdScale[key] = [0.092]*4+[0.058]*4 #down/up\n",
    "                ttH_pdf[key] = [0.036]*4\n",
    "            mc_stats[k] = []\n",
    "            if p == 'ggZH': scaling[key] = [0.2]*4\n",
    "            else: scaling[key] = [0,0,0,0]\n",
    "\n",
    "\n",
    "sig_eff = [lumi, muonVeto, jetVeto,rechitVeto,time, time_spread, cut_based_eff_unc, clusterEff_unc,readout, JES,pileup, \\\n",
    "           ggH_higgsPt, VBFH_higgsPt, WH_higgsPt, ZH_higgsPt, ttH_higgsPt, ggZH_higgsPt,  \\\n",
    "           ggH_qcdScale, VBFH_qcdScale, WH_qcdScale, ZH_qcdScale, ttH_qcdScale, ggZH_qcdScale, \\\n",
    "           ggH_pdf,VBFH_pdf, WH_pdf, ZH_pdf, ttH_pdf, ggZH_pdf,\\\n",
    "           scaling, mc_stats]\n",
    "sig_eff_name = ['lumi','muonVeto','jetVeto','rechitVeto','time','time_spread','cut_based_eff_unc', 'clusterEff_unc', 'readout', 'JES','pileup', \\\n",
    "                'ggH_higgsPt', 'VBFH_higgsPt', 'WH_higgsPt', 'ZH_higgsPt', 'ttH_higgsPt', 'ggZH_higgsPt',\\\n",
    "                'ggH_qcdScale', 'VBFH_qcdScale', 'WH_qcdScale', 'ZH_qcdScale', 'ttH_qcdScale', 'ggZH_qcdScale', \\\n",
    "                'ggH_pdf','VBFH_pdf', 'WH_pdf', 'ZH_pdf', 'ttH_pdf', 'ggZH_pdf',\\\n",
    "                'ggZH_reweight','mc_stats']\n",
    "\n",
    "\n",
    "assert(len(sig_eff)==len(sig_eff_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8953452999999999\n"
     ]
    }
   ],
   "source": [
    "signal_correction = (1-0.015)*(1-0.033)*(1-0.060)\n",
    "print(signal_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 60  70  80  90 100 110 120 130 140 150 160 170 180 190 200 210]\n",
      "130 [ 3 96 47  3] []\n",
      "/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine/datacards_2tag/V1p17/v2/v138//v1/unblind//csc/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:144: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:144: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:144: RuntimeWarning: overflow encountered in square\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import importlib\n",
    "importlib.reload(sys.modules['helper'])\n",
    "from helper import make_datacard, make_datacard_2sig, weight_calc\n",
    "#methodB use oot vr and ABCD method\n",
    "#methodC use the fit functions\n",
    "N_RECHIT_CUTS = np.arange(60,220, 10)\n",
    "# N_RECHIT_CUTS = [130]\n",
    "ctaus = ['5','10','15','20','30','40', '50','60', '100', '125','150','200','300','500','600','700','800','900','1000', '2000','3000','4000', '5000', '6000','7000','8000','10000', '20000','30000','50000',\\\n",
    "         '100000', '200000', '300000', '500000', '1000000', '2000000', '3000000', '5000000', '6000000', '10000000'] #mm\n",
    "UNBLIND = 2\n",
    "# 0 use OOT region, 1 unblind ABC, 2 unblind ABCD\n",
    "method = 2\n",
    "fit_function = 'se' #se, me, sp\n",
    "jetmet=0\n",
    "datacard_version  = 'v1'\n",
    "\n",
    "bkg_unc = [] #ABCD closure, sum of stats from two VR\n",
    "bkg_unc_name = []\n",
    "var = dphiMet_cluster\n",
    "DPHI_CUT = 0.75\n",
    "DPHI_CUTS = [0.75]\n",
    "removeOverlap = 0\n",
    "# print(bdtBkgEff_nrechit.shape)\n",
    "bkg = []\n",
    "print(N_RECHIT_CUTS)\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "    if not N_RECHIT_CUT==130:continue\n",
    "    for DPHI_CUT in DPHI_CUTS:\n",
    "        bkg_unc = []\n",
    "       \n",
    "        \n",
    "        k = 'data_intime_sr'\n",
    "        if removeOverlap:\n",
    "            a = np.count_nonzero(np.logical_and(np.logical_not(two_tag[k]), np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT)))\n",
    "            b = np.count_nonzero(np.logical_and(np.logical_not(two_tag[k]), np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT)))\n",
    "            c = np.count_nonzero(np.logical_and(np.logical_not(two_tag[k]), np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT)))\n",
    "            d = np.count_nonzero(np.logical_and(np.logical_not(two_tag[k]), np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT))) \n",
    "        else:\n",
    "            a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "            b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "            c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT))\n",
    "            d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT))\n",
    "        bkg_rate = np.array([a,b,c,a*c/b])\n",
    "        if UNBLIND == 1:observation= np.array([a,b,c,a*c/b])\n",
    "        else: observation= np.array([a,b,c,d])\n",
    "        print(N_RECHIT_CUT, observation, bkg_unc)\n",
    "        \n",
    "        #####\n",
    "        # a = c*c1*c2\n",
    "        # b = c1* c\n",
    "        # c = c\n",
    "        # d = c2*c\n",
    "        # start adding signal\n",
    "        #####\n",
    "#         /storage/af/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine/datacards_2tag/V1p17/v1/v137/v1/unblind/csc\n",
    "        outDataCardsDir = '/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine/datacards_2tag/'+\\\n",
    "        ntupler_version+analyzer_version+'/'\n",
    "#         if cut_based:outDataCardsDir += 'cut_based_'+cut_based_version+'/'\n",
    "#         else: outDataCardsDir += bdt_name+'/'\n",
    "        outDataCardsDir += datacard_version+'/'\n",
    "        if UNBLIND == 0: outDataCardsDir += 'blind/'\n",
    "        elif UNBLIND == 1: outDataCardsDir += 'unblindABC/'\n",
    "        else:outDataCardsDir += 'unblind/'\n",
    "        if removeOverlap: outDataCardsDir += '/csc_removeOverlap/'\n",
    "        else: outDataCardsDir += '/csc/'\n",
    "        if not os.path.isdir(outDataCardsDir):os.makedirs(outDataCardsDir)\n",
    "        print(outDataCardsDir)\n",
    "        sig_norm = []\n",
    "        for m in mass:\n",
    "            for ct in ctaus:\n",
    "                dphi = str(DPHI_CUT).replace(\".\", \"p\")\n",
    "                if len(prod) == 5: modelName = 'allProd_HToSSTo'+decay\n",
    "                elif len(prod) ==6:  modelName = 'allProd_withggZH_HToSSTo'+decay\n",
    "                else: modelName = ('_').join(prod)+'_HToSSTo'+decay\n",
    "                modelName = modelName + '_mh125_mx'+str(m)+'_ctau'+str(ct)+'mm_nRechit'+str(N_RECHIT_CUT)+'dPhiCluster'+dphi\n",
    "                \n",
    "                signal_rate = {}\n",
    "                mc_stat_unc = {}\n",
    "                gmn = {}\n",
    "                sig_unc = {}\n",
    "                ctf = int(ct)\n",
    "                ct_list = 10**int(math.log10(ctf))\n",
    "                if ctf < OLD_CTAU[0]: ct_list = [OLD_CTAU[0]]\n",
    "                elif ctf>OLD_CTAU[-1]: ct_list = [OLD_CTAU[-1]]\n",
    "                elif ct_list == int(ct): ct_list = [int(ct)]\n",
    "                else:ct_list = [ct_list,ct_list*10]\n",
    "                for p in prod:                    \n",
    "                    signal_rate[p] = np.zeros((4,))\n",
    "                    mc_stat_unc[p] = np.zeros((4,))\n",
    "                    gmn[p] = np.zeros((4,))\n",
    "                    sig_unc[p] = []\n",
    "                    if p == 'others':\n",
    "                        for i in range(4):\n",
    "                            signal_rate[p][i] = signal_rate['ggH'][i]*0.52\n",
    "                            mc_stat_unc[p][i] = (mc_stat_unc['ggH'][i]*signal_rate[p][i])**2\n",
    "                    else:\n",
    "                        for i, ct0 in enumerate(ct_list):\n",
    "                            k = 'MC_'+p+'_'+str(m)+'_'+str(ct0)\n",
    "                            T = tree[k]\n",
    "                            if np.count_nonzero(sel_ev[k])==0:continue\n",
    "#                             gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                            gLLP_ctau = T.array('gLLP_ctau')[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "                            weight_ctau = weight_calc(gLLP_ctau, int(ct)/10, int(ct0)/10) # convert everything to cm\n",
    "                            gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                            if len(ct_list) == 1:weight_cond = gLLP_ctau >= 0\n",
    "                            else:\n",
    "                                if i == 0 : weight_cond = gLLP_ctau<int(ct_list[0]/2)\n",
    "                                else: weight_cond = gLLP_ctau>=int(ct_list[0]/2)\n",
    "                            w = weight[k]*weight_ctau\n",
    "                            if removeOverlap: cond = np.logical_and(np.logical_not(two_tag[k]), np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]>=DPHI_CUT), weight_cond))\n",
    "                            else:cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]>=DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][0]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][0]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][0] += len(w[cond])\n",
    "                            if removeOverlap: cond = np.logical_and(np.logical_not(two_tag[k]), np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]>=DPHI_CUT), weight_cond))\n",
    "                            else:cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]>=DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][1]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][1]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][1] += len(w[cond])\n",
    "                            if removeOverlap: cond = np.logical_and(np.logical_not(two_tag[k]), np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]<DPHI_CUT), weight_cond))\n",
    "                            else:cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]<DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][2]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][2]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][2] += len(w[cond])\n",
    "                            if removeOverlap: cond = np.logical_and(np.logical_not(two_tag[k]), np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]<DPHI_CUT), weight_cond))\n",
    "                            else:cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]<DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][3]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][3]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][3] += len(w[cond])\n",
    "                            # apply the corrections\n",
    "                            for j in [0,1,2,3]:\n",
    "                                if signal_rate[p][j]<0.0:\n",
    "                                    signal_rate[p][j]=0.0\n",
    "                                    mc_stat_unc[p][j]=0.0\n",
    "                                    gmn[p][j] = 0.0\n",
    "                                else:\n",
    "                                    signal_rate[p][j] *= signal_correction\n",
    "\n",
    "#                     mc_stat_unc[p] = list(np.nan_to_num(np.sqrt(mc_stat_unc[p])/signal_rate[p])) #convert absolute to relative uncertainty\n",
    "                    \n",
    "                    mc_stat_unc[p] = np.nan_to_num(signal_rate[p]/np.sqrt(mc_stat_unc[p]))**2 #gmn\n",
    "                    mc_stat_unc[p][mc_stat_unc[p] == np.inf] = 0.0\n",
    "                    \n",
    "                    mc_stat_unc[p] = list(mc_stat_unc[p])\n",
    "                    mc_stat_unc[p] = list(gmn[p])\n",
    "                    if p == 'others': k = k.replace(\"ggH\", \"others\")\n",
    "                    for j, ele in enumerate(sig_eff):# go through each uncertainty\n",
    "                        if j == len(sig_eff)-1: # if mc_stats\n",
    "                            sig_unc[p].append(mc_stat_unc[p])\n",
    "#                         elif sig_eff_name[j] in simulation_name:\n",
    "# #                             print(type(ele[k]))\n",
    "#                             sig_unc[p].append(np.array(ele[k])*0.5)\n",
    "                        else:\n",
    "                            sig_unc[p].append(ele[k])\n",
    "                   \n",
    "                \n",
    "                norm = np.sum(signal_rate['ggH'])/4\n",
    "#                 if norm == 0.0:continue\n",
    "#                 for k,v in signal_rate.items():signal_rate[k] = v/norm\n",
    "#                 print(modelName, norm, signal_rate['ggH'], mc_stat_unc['ggH'])\n",
    "                make_datacard_2tag(outDataCardsDir, modelName, signal_rate, norm, bkg_rate, observation, \\\n",
    "                                  bkg_unc, bkg_unc_name, sig_unc, sig_eff_name, 'd','')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unblind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nrechits, A, B, C, pred, D\n",
      "60 \t 47 \t 52 \t 20 \t 30 \t 18.08 \t 5.44\n",
      "70 \t 22 \t 77 \t 32 \t 18 \t 9.14 \t 2.74\n",
      "80 \t 11 \t 88 \t 38 \t 12 \t 4.75 \t 1.7\n",
      "90 \t 9 \t 90 \t 42 \t 8 \t 4.2 \t 1.6\n",
      "100 \t 3 \t 96 \t 42 \t 8 \t 1.31 \t 0.8\n",
      "110 \t 3 \t 96 \t 42 \t 8 \t 1.31 \t 0.8\n",
      "120 \t 3 \t 96 \t 43 \t 7 \t 1.34 \t 0.81\n",
      "130 \t 3 \t 96 \t 47 \t 3 \t 1.47 \t 0.89\n",
      "140 \t 2 \t 97 \t 47 \t 3 \t 0.97 \t 0.71\n",
      "150 \t 2 \t 97 \t 47 \t 3 \t 0.97 \t 0.71\n",
      "160 \t 2 \t 97 \t 48 \t 2 \t 0.99 \t 0.72\n",
      "170 \t 1 \t 98 \t 49 \t 1 \t 0.5 \t 0.51\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-5c4a17b991ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnCsc_JetMuonVetoCluster0p4_Me1112Veto\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mN_RECHIT_CUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mDPHI_CUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0munc_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     print(N_RECHIT_CUT, '\\t',a,'\\t',b,'\\t',c,'\\t',d,'\\t', round(c/b*a, 2), '\\t',\\\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "k = 'data_intime_sr'\n",
    "\n",
    "n_ev = 5000\n",
    "var = np.abs(dphiMet_cluster[k])\n",
    "DPHI_CUT = 0.75\n",
    "print(\"Nrechits, A, B, C, pred, D\")\n",
    "for N_RECHIT_CUT in np.arange(60,240,10):\n",
    "    a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var>=DPHI_CUT))\n",
    "    b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var>=DPHI_CUT))\n",
    "    c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var<DPHI_CUT))\n",
    "    d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var<DPHI_CUT))\n",
    "    pred = c/b*a\n",
    "    unc_pred = (1./c + 1./b + 1./a)**0.5*(c/b*a)\n",
    "\n",
    "    print(N_RECHIT_CUT, '\\t',a,'\\t',b,'\\t',c,'\\t',d,'\\t', round(c/b*a, 2), '\\t',\\\n",
    "          round( (1./c + 1./b + 1./a)**0.5*(c/b*a), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
