{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/02\n",
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "# MET trigger efficiency measurement\n",
    "\n",
    "import ROOT as rt\n",
    "# import root_numpy as rtnp\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import awkward\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "sys.path.append('/storage/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/python/')\n",
    "from helper import make_datacard, make_datacard_2sig, weight_calc\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot,make_ratio_pEff\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "\n",
    "wH = 1\n",
    "Z_MASS = 91.2\n",
    "\n",
    "\n",
    "# donotdelete = []\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyToyear(key):\n",
    "    for year in years:\n",
    "        if year in key:\n",
    "            return year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/Data2018ABC_AOD/v5//v64//normalized/Run2_displacedJetMuonNtupler_V1p17_Data2018_AOD_17Sept2018_Run2018-17Sep2018_goodLumi.root\n",
      "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Fall18/v2//v64//normalized/WJetsToLNu_HT-70ToInf_TuneCP5_13TeV-madgraphMLM-pythia8_1pb_weighted.root\n"
     ]
    }
   ],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "\n",
    "\n",
    "mc_years = ['Summer16', 'Fall17', 'Fall18']\n",
    "data_years = ['Data2016', 'Data2017', 'Data2018ABC']\n",
    "year =2\n",
    "if year ==0:tune = 'TuneCUETP8M1'\n",
    "else: tune = 'TuneCP5'\n",
    "lumi = [35.92 * 1000, 41.53 * 1000, 59.74 * 1000,]\n",
    "ntupler_version = 'V1p17/'\n",
    "analyzer_version = '/v64/'\n",
    "\n",
    "\n",
    "data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/'+data_years[year]+'_AOD/v5/'+analyzer_version+'/normalized/'\n",
    "if year == 0: \n",
    "    fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p17_Data2016_AOD_Run2016-07Aug17_goodLumi.root'\n",
    "elif year == 1:\n",
    "    fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p17_Data2017_AOD_Run2017-17Nov2017_goodLumi.root'\n",
    "else: \n",
    "    fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p17_Data2018_AOD_17Sept2018_Run2018-17Sep2018_goodLumi.root'\n",
    "mc_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_'+mc_years[year]+'/v2/'+analyzer_version+'/normalized/'\n",
    "fpath['mc'] = mc_path+'WJetsToLNu_HT-70ToInf_'+tune+'_13TeV-madgraphMLM-pythia8_1pb_weighted.root'\n",
    "\n",
    "NEvents = {}\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    print(v)\n",
    "    root_dir = uproot.open(v) \n",
    "    if not root_dir: \n",
    "        print(k, \"zombie\")\n",
    "        continue\n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]\n",
    "    w = tree[k][\"weight\"].array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/Data2016_AOD/v5//v64//normalized/Run2_displacedJetMuonNtupler_V1p17_Data2016_AOD_Run2016-07Aug17_goodLumi.root\n",
    "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Summer16/v2//v64//normalized/WJetsToLNu_HT-70ToInf_TuneCUETP8M1_13TeV-madgraphMLM-pythia8_1pb_weighted.root\n",
    "\n",
    "\n",
    "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/Data2017_AOD/v5//v64//normalized/Run2_displacedJetMuonNtupler_V1p17_Data2017_AOD_Run2017-17Nov2017_goodLumi.root\n",
    "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Fall17/v2//v64//normalized/WJetsToLNu_HT-70ToInf_TuneCP5_13TeV-madgraphMLM-pythia8_1pb_weighted.root\n",
    "\n",
    "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/Data2018ABC_AOD/v5//v64//normalized/Run2_displacedJetMuonNtupler_V1p17_Data2018_AOD_17Sept2018_Run2018-17Sep2018_goodLumi.root\n",
    "/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/MC_Fall18/v2//v64//normalized/WJetsToLNu_HT-70ToInf_TuneCP5_13TeV-madgraphMLM-pythia8_1pb_weighted.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc with different hit vetoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 72188584.0\n",
      "mc 236.49712\n",
      "CPU times: user 47 s, sys: 18.8 s, total: 1min 5s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sel_ev = {}\n",
    "HLT_PFMET120_PFMHT120_IDTight = {}\n",
    "HLT_PFMETNoMu120_PFMHTNoMu120_IDTight = {}\n",
    "HLT_PFMET140_PFMHT140_IDTight = {}\n",
    "HLT_PFMET120_PFMHT120_IDTight_PFHT60 = {}\n",
    "HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 = {}\n",
    "HLT_PFMETNoMu140_PFMHTNoMu140_IDTight = {}\n",
    "met = {}\n",
    "metNoMu = {}\n",
    "METTrigger = {}\n",
    "weight = {}\n",
    "lepPt = {}\n",
    "HLT_PFMETNoMu = {}\n",
    "HLT_PFMET = {}\n",
    "for k, T in tree.items():\n",
    "\n",
    "########### SELECTION: EVENTS ############\n",
    "\n",
    "    sel_muon = np.logical_and(T.array('lepPt')<100, np.abs(T.array('lepPdgId'))==13)\n",
    "#     sel_ele = np.logical_and(T.array('lepPt')<300, np.abs(T.array('lepPdgId'))==11)\n",
    "    sel_ele = np.abs(T.array('lepPdgId'))==11\n",
    "\n",
    "\n",
    "#     sel_ev[k] = np.logical_and(T.array('HLT_IsoMu27'),sel_muon.sum()>0)\n",
    "    sel_ev[k] = np.logical_and(T.array('HLT_IsoEle'),sel_ele.sum()>0)\n",
    "\n",
    "\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k], T.array('Flag2_all'))\n",
    "\n",
    "\n",
    "\n",
    "    HLT_PFMET120_PFMHT120_IDTight[k] = T.array('HLT_PFMET120_PFMHT120_IDTight')[sel_ev[k]]\n",
    "    HLT_PFMETNoMu120_PFMHTNoMu120_IDTight[k] = T.array('HLT_PFMETNoMu120_PFMHTNoMu120_IDTight')[sel_ev[k]]\n",
    "    HLT_PFMET140_PFMHT140_IDTight[k] = T.array('HLT_PFMET140_PFMHT140_IDTight')[sel_ev[k]]\n",
    "    HLT_PFMET120_PFMHT120_IDTight_PFHT60[k] = T.array('HLT_PFMET120_PFMHT120_IDTight_PFHT60')[sel_ev[k]]\n",
    "    HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60[k] = T.array('HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60')[sel_ev[k]]\n",
    "    HLT_PFMETNoMu140_PFMHTNoMu140_IDTight[k] = T.array('HLT_PFMETNoMu140_PFMHTNoMu140_IDTight')[sel_ev[k]]\n",
    "    if year == 0: HLT_PFMETNoMu[k] = HLT_PFMETNoMu120_PFMHTNoMu120_IDTight[k]\n",
    "    else: HLT_PFMETNoMu[k] = np.logical_or(np.logical_or(HLT_PFMETNoMu120_PFMHTNoMu120_IDTight[k], HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60[k]), HLT_PFMETNoMu140_PFMHTNoMu140_IDTight[k])\n",
    "    if year == 0: HLT_PFMET[k] = HLT_PFMET120_PFMHT120_IDTight[k]\n",
    "    else: HLT_PFMET[k] = np.logical_or(np.logical_or(HLT_PFMET120_PFMHT120_IDTight[k], HLT_PFMET120_PFMHT120_IDTight_PFHT60[k]), HLT_PFMET140_PFMHT140_IDTight[k])\n",
    "\n",
    "#     else:\n",
    "#     sel_ev[k] = T.array('HLTDecision')[:,136]\n",
    "#     HLT_PFMET120_PFMHT120_IDTight[k] = T.array('HLTDecision')[:,310][sel_ev[k]]\n",
    "#     HLT_PFMETNoMu120_PFMHTNoMu120_IDTight[k] = T.array('HLTDecision')[:,467][sel_ev[k]]\n",
    "#     HLT_PFMET140_PFMHT140_IDTight[k] = T.array('HLTDecision')[:,703][sel_ev[k]]\n",
    "#     HLT_PFMET120_PFMHT120_IDTight_PFHT60[k] =T.array('HLTDecision')[:,709][sel_ev[k]]\n",
    "#     HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60[k] = T.array('HLTDecision')[:,710][sel_ev[k]]\n",
    "#     HLT_PFMETNoMu140_PFMHTNoMu140_IDTight[k] = T.array('HLTDecision')[:,717][sel_ev[k]]\n",
    "\n",
    "\n",
    "#     lepPt[k] = T.array('lepPt')[sel_ev[k]][:,0]\n",
    "    weight[k] = (T.array('weight')*T.array('pileupWeight'))[sel_ev[k]]\n",
    "    if k == 'data':weight[k] = weight[k]*0.0+1.0\n",
    "    METTrigger[k] = T.array('METTrigger')[sel_ev[k]]\n",
    "    met[k] = T.array('met')[sel_ev[k]]\n",
    "    metNoMu[k] = T.array('metNoMu')[sel_ev[k]]\n",
    "    print(k,np.sum(weight[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(sys.modules['histo_utilities'])\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot, make_ratio_pEff\n",
    "\n",
    "var = [met, metNoMu]\n",
    "title = ['MET [GeV]', 'MET_NoMu [GeV]']\n",
    "names = ['met', 'metNoMu']\n",
    "yaxis = ['Trigger Efficiency', 'Events', 'Events']\n",
    "cond_var = [HLT_PFMET,HLT_PFMETNoMu, METTrigger]\n",
    "cond_name=['met_trig', 'metNoMu_trig', 'all_trig']\n",
    "for plot in range(3):\n",
    "    for j in range(len(title)):\n",
    "        for m, cond in enumerate(cond_var):\n",
    "#             if not(plot==0 and j == 1 and m == 2):continue\n",
    "            c = rt.TCanvas('c','c', 800, 600)\n",
    "            if plot ==0:leg = rt.TLegend(0.2,0.80,0.4,0.90)\n",
    "            else: leg = rt.TLegend(0.7,0.80,0.9,0.90)\n",
    "            leg.SetTextSize(0.03)\n",
    "            leg.SetBorderSize(0)\n",
    "            leg.SetEntrySeparation(0.01)\n",
    "            hm = {}\n",
    "            hb = {}\n",
    "            pEff={}\n",
    "            for i,k in enumerate(tree.keys()):\n",
    "                if k == 'data': luminosity = 1\n",
    "                else: luminosity = lumi[year]\n",
    "                bins = list(np.arange(0,400,20))+[400,450, 600,700,800,1000]\n",
    "#                 bins = [30,0,600]\n",
    "#                 bins = [25,0,500]\n",
    "#                 arr[arr > 255] = x\n",
    "                temp = var[j][k]\n",
    "#                 temp[temp>499] = 499\n",
    "                hm[k] = create_TH1D(temp[cond[k]], 'hm1', axis_title = [title[j],yaxis[plot]], binning=bins, weights = weight[k][cond[k]]*luminosity) \n",
    "                hb[k] = create_TH1D(temp, 'hb1', axis_title = [title[j],yaxis[plot]], binning=bins, weights =  weight[k]*luminosity) \n",
    "#                 hm[k] = create_TH1D(np.abs(var[j][k][cond[k]]), 'hm1', axis_title = [title[j],yaxis[plot]], binning=bins, weights = weight[k][cond[k]]*luminosity) \n",
    "#                 hb[k] = create_TH1D(np.abs(var[j][k]), 'hb1', axis_title = [title[j],yaxis[plot]], binning=bins, weights =  weight[k]*luminosity) \n",
    "                pEff[k] = rt.TEfficiency(hm[k],hb[k])\n",
    "                pEff[k].SetLineColor(std_color_list[i])\n",
    "                hm[k].SetLineColor(std_color_list[i])\n",
    "                hb[k].SetLineColor(std_color_list[i])\n",
    "                pEff[k].SetLineWidth(2)\n",
    "                hm[k].SetLineWidth(2)\n",
    "                hb[k].SetLineWidth(2)\n",
    "                print(k, luminosity, hb[k].Integral(),hm[k].Integral())\n",
    "                if plot == 0:\n",
    "                    leg.AddEntry(pEff[k],k)\n",
    "                    pEff[k].Draw('' if i==0 else 'same')\n",
    "                    file_name = 'efficiency'\n",
    "                elif plot == 1:\n",
    "                    leg.AddEntry(hb[k],k)\n",
    "                    hb[k].Draw('hist same')\n",
    "                    file_name = 'denominator'\n",
    "                else:\n",
    "                    leg.AddEntry(hm[k],k)\n",
    "                    hm[k].Draw('hist same')\n",
    "                    file_name = 'nominator'\n",
    "            if plot == 0:\n",
    "                c = make_ratio_pEff([pEff['mc'], pEff['data']], fit = False, logy=False, in_tags = [\"WJets\",\"Data\"], ratio_bounds = [0,1.5], draw_opt = ['E1','E1'])\n",
    "\n",
    "            elif plot == 1:\n",
    "                c = make_ratio_plot([hb['mc'], hb['data']], fit = False, logy=True, in_tags = [\"WJets\",\"Data\"], ratio_bounds = [0,3], draw_opt = ['E1','E1'])\n",
    "            else:\n",
    "                c = make_ratio_plot([hm['mc'], hm['data']], fit = False, logy=True, in_tags = [\"WJets\",\"Data\"], ratio_bounds = [0,3], draw_opt = ['E1','E1'])\n",
    " \n",
    "\n",
    "    #         leg.Draw()\n",
    "            if plot>0:c.SetLogy()\n",
    "            c.Draw()\n",
    "            c.SaveAs('/storage/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/plots/MuonSystem_Analysis/trigger_efficiency/'+analyzer_version+mc_years[year]+'_'+names[j]+\"_\"+cond_name[m]+'_'+file_name+'.png')\n",
    "            c.SaveAs('/storage/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/plots/MuonSystem_Analysis/trigger_efficiency/'+analyzer_version+mc_years[year]+'_'+names[j]+\"_\"+cond_name[m]+'_'+file_name+'.C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save ratio to ROOT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 0.5235371597458819\n",
      "30.0 0.573686985200462\n",
      "50.0 0.3598441215951867\n",
      "70.0 0.3648966851824489\n",
      "90.0 0.4238907955560277\n",
      "110.0 0.47703373601450894\n",
      "130.0 0.5151279796514888\n",
      "150.0 0.5666473016289832\n",
      "170.0 0.6719704011340446\n",
      "190.0 0.7740997268000165\n",
      "210.0 0.8583412693047137\n",
      "230.0 0.9114181753951717\n",
      "250.0 0.9434488625816531\n",
      "270.0 0.9570039450279302\n",
      "290.0 0.9606727021788551\n",
      "310.0 0.9642929525494447\n",
      "330.0 0.9662979678457121\n",
      "350.0 0.9618796861203044\n",
      "370.0 0.9566440277319069\n",
      "390.0 0.9608722967485552\n",
      "425.0 0.9533138670585112\n",
      "525.0 0.9580092314832613\n",
      "650.0 0.9478094342730914\n",
      "750.0 0.930077599087426\n",
      "900.0 0.897688435079022\n",
      "1020.0 0.7452043591476072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TROOT::Append>: Replacing existing TH1: hm1 (Potential memory leak).\n",
      "Warning in <TROOT::Append>: Replacing existing TH1: hb1 (Potential memory leak).\n",
      "Info in <TEfficiency::TEfficiency>: given histograms are filled with weights\n",
      "Info in <TROOT::TEfficiency::SetUseWeightedEvents>: Handle weighted events for computing efficiency\n",
      "Warning in <TEfficiency::GetEfficiencyErrorLow>: frequentist confidence intervals for weights are only supported by the normal approximation\n",
      "Info in <TEfficiency::GetEfficiencyErrorLow>: setting statistic option to kFNormal\n"
     ]
    }
   ],
   "source": [
    "outputDir = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/ScaleFactors/'\n",
    "outputFileName = outputDir+'METTriggers_SF.root'\n",
    "# outFile = rt.TFile(outputFileName, 'UPDATE')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hm = {}\n",
    "hb = {}\n",
    "pEff={}\n",
    "bins = [30,0,600]\n",
    "bins = list(np.arange(0,400,20))+[400,450, 600,700,800,1000]\n",
    "\n",
    "\n",
    "for i,k in enumerate(tree.keys()):\n",
    "    cond = HLT_PFMETNoMu[k]\n",
    "    if k == 'data': luminosity = 1\n",
    "    else: luminosity = lumi[year]\n",
    "    hm[k] = create_TH1D(np.abs(metNoMu[k][cond]), 'hm1', axis_title = ['MET','Efficiency'], binning=bins, weights = weight[k][cond]*luminosity) \n",
    "    hb[k] = create_TH1D(np.abs(metNoMu[k]), 'hb1', axis_title = ['MET','Efficiency'], binning=bins, weights =  weight[k]*luminosity) \n",
    "    pEff[k] = rt.TEfficiency(hm[k],hb[k])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "nom = pEff['data'].GetCopyPassedHisto()\n",
    "denom = pEff['mc'].GetCopyPassedHisto()\n",
    "nom.SetLineColor(pEff['data'].GetLineColor())\n",
    "#set relative error of ratio to be the relative error of data\n",
    "for j in range(nom.GetXaxis().GetNbins()+1):\n",
    "    nom.SetBinContent(j+1,pEff['data'].GetEfficiency(j+1))\n",
    "    denom.SetBinContent(j+1,pEff['mc'].GetEfficiency(j+1))\n",
    "    nom.SetBinError(j+1,max(pEff['data'].GetEfficiencyErrorLow(j+1), pEff['data'].GetEfficiencyErrorUp(j+1)))\n",
    "    denom.SetBinError(j+1,max(pEff['mc'].GetEfficiencyErrorLow(j+1), pEff['mc'].GetEfficiencyErrorUp(j+1)))\n",
    "nom.Divide(denom)\n",
    "    \n",
    "for i in range(nom.GetXaxis().GetNbins()+1):\n",
    "    print(nom.GetBinCenter(i+1), nom.GetBinContent(i+1))\n",
    "\n",
    "# Normalize(histPt)\n",
    "\n",
    "# outFile.WriteTObject(nom, 'trigger_efficiency_'+mc_years[year], \"WriteDelete\");\n",
    "# outFile.Close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
