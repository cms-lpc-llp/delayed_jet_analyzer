{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "# with all production modes\n",
    "# make corrections to signal yield for the simulation modelling uncertainties and create datacard\n",
    "\n",
    "import ROOT as rt\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import os\n",
    "\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "import awkward\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/af/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "sys.path.append('/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/python/')\n",
    "from helper import make_datacard, make_datacard_2sig, weight_calc\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "\n",
    "\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC_ggH_7_100 6976137.0\n",
      "MC_ggH_7_1000 6873999.0\n",
      "MC_ggH_7_10000 6904000.0\n",
      "MC_ggH_7_100000 6847000.0\n",
      "MC_ggH_15_100 6780999.0\n",
      "MC_ggH_15_1000 6784000.0\n",
      "MC_ggH_15_10000 6960000.0\n",
      "MC_ggH_15_100000 6929000.0\n",
      "MC_ggH_40_100 6665000.0\n",
      "MC_ggH_40_1000 6843000.0\n",
      "MC_ggH_40_10000 6848000.0\n",
      "MC_ggH_40_100000 6897998.0\n",
      "MC_ggH_55_100 6773000.0\n",
      "MC_ggH_55_1000 6828000.0\n",
      "MC_ggH_55_10000 6871129.0\n",
      "MC_ggH_55_100000 6751000.0\n"
     ]
    }
   ],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "mass = [15, 40, 55]\n",
    "\n",
    "# prod = ['ggH', 'VBFH_H','ZH', 'WH', 'ttH_H','ggZH']\n",
    "# decay = 'dddd'\n",
    "\n",
    "\n",
    "prod = ['ggH','VBFH','ZH', 'WH', 'ttH_H','ggZH']\n",
    "prod = ['ggH']\n",
    "decay = '4Tau'\n",
    "\n",
    "# prod = ['ggH','VBFH','ZH', 'WH', 'ttH_H','ggZH']\n",
    "# decay = 'bbbb'\n",
    "\n",
    "\n",
    "mass = [15, 40, 55]\n",
    "if not decay == 'bbbb': mass = [7, 15, 40, 55]\n",
    "\n",
    "OLD_CTAU = np.array([100, 1000, 10000, 100000])#in mm\n",
    "\n",
    "ntupler_version = 'V1p17/'\n",
    "\n",
    "data_path = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/V1p17/Data2018/v5/v100/normalized/'\n",
    "# fpath['data'] = '/storage/af/user/christiw/login-1/christiw/LLP/displacedJetMuonAnalyzer/csc/V1p17//Data2018//v5/v127//normalized/Run2_displacedJetMuonNtupler_V1p17_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "\n",
    "fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p17_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "mc_path = {}\n",
    "\n",
    "analyzer_version = 'v1/v106/'\n",
    "mc_path['ggH'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_all/'+analyzer_version+'/normalized/'\n",
    "mc_path['VBFH'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_all/'+analyzer_version+'/normalized/'\n",
    "analyzer_version = 'v2/v106/'\n",
    "mc_path['ZH'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['WH'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['WminusH'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['WplusH'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['ttH_H'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['VBFH_H'] = '/storage/cms/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/'+ntupler_version+'/MC_Fall18/'+analyzer_version+'/normalized/'\n",
    "mc_path['ggZH'] = mc_path['ZH']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "        for p in prod:\n",
    "            if p == 'others':continue\n",
    "            if p == 'VBFH' and decay == 'bbbb':\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "                fpath[key] = mc_path[p]+p+'_HToSSTo4b_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_137000pb_weighted.root'\n",
    "            elif p == 'ggH' or p == 'VBFH':\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "                fpath[key] = mc_path[p]+p+'_HToSSTo'+decay+'_MH-125_MS-'+str(m)+'_ctau-'+str(ct)+'_137000pb_weighted.root'\n",
    "            elif p == 'VBFH_H':\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)  \n",
    "                fpath[key] = mc_path[p]+'VBFHToSS_STodd_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "            else:\n",
    "                key = 'MC_'+p+'_'+str(m)+'_'+str(ct)                       \n",
    "                if decay == 'bbbb':fpath[key] = mc_path[p] + p+'ToSS_SToBB_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                if decay == 'dddd':fpath[key] = mc_path[p] + p+'ToSS_STodd_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                if decay == '4Tau':fpath[key] = mc_path[p] + p+'ToSS_SToTauTau_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                if p == 'ggZH':\n",
    "                    if decay == 'bbbb':fpath[key] = mc_path[p] + 'ZHToSS_SToBB_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                    if decay == 'dddd':fpath[key] = mc_path[p] + 'ZHToSS_STodd_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "                    if decay == '4Tau':fpath[key] = mc_path[p] + 'ZHToSS_SToTauTau_ms'+str(m)+'_pl'+str(ct)+'_137000pb_weighted.root'\n",
    "\n",
    "\n",
    "# fpath['hnl']= '/storage/af/user/christiw/HNL_electronType_ms5p0_plVe2_1e-5/HeavyNeutralLepton_Tree.root'                        \n",
    "NEvents = {}\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    root_dir = uproot.open(v) \n",
    "    if not root_dir: \n",
    "        print(k, \"zombie\")\n",
    "        continue\n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]\n",
    "    \n",
    "    w = tree[k][\"weight\"].array()\n",
    "    if not 'data' in k: \n",
    "        print(k, root_dir['NEvents']._fEntries)\n",
    "        \n",
    "\n",
    "\n",
    "root_dir = uproot.open('/storage/af/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/HiggsPtWeights/ZHToggZH_HiggsPtReweight.root') \n",
    "h_reweight = root_dir['higgsPthiggsEta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "NStation_ratio = [0.8153731, 1.135363]\n",
    "AvgStation_ratio = [0.5585293, 1.070362, 1.320824, 0.9593284]\n",
    "Eta_ratio = [1.0, 0.2841959,0.5748884,0.6125545,1.038548,1.184251,1.352579,0.5508717,0.82808,1.382264,1.030224,1.223585]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc with different hit vetoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC_ggH_7_100 \t 0.0348314606741573\n",
      "MC_ggH_7_1000 \t 0.016753926701570682\n",
      "MC_ggH_7_10000 \t 0.0028653295128939827\n",
      "MC_ggH_7_100000 \t 0.0\n",
      "MC_ggH_15_100 \t 0.010666666666666666\n",
      "MC_ggH_15_1000 \t 0.030179445350734094\n",
      "MC_ggH_15_10000 \t 0.001483679525222552\n",
      "MC_ggH_15_100000 \t 0.0\n",
      "MC_ggH_40_100 \t 0.0\n",
      "MC_ggH_40_1000 \t 0.05069124423963134\n",
      "MC_ggH_40_10000 \t 0.014877102199223804\n",
      "MC_ggH_40_100000 \t 0.0\n",
      "MC_ggH_55_100 \t 0.0\n",
      "MC_ggH_55_1000 \t 0.03067484662576687\n",
      "MC_ggH_55_10000 \t 0.007226236798221234\n",
      "MC_ggH_55_100000 \t 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "JET_PT_CUT = 10.0\n",
    "MUON_PT_CUT = 20.0\n",
    "N_RECHIT_CUT = 90\n",
    "jetPt_cut = 50\n",
    "tightid = False\n",
    "ring_cut = 50\n",
    "cut_based = True\n",
    "cut_based_version = 'v4'\n",
    "\n",
    "intime = True\n",
    "DPHI_CUT = 1\n",
    "weight = {}\n",
    "\n",
    "nCsc_JetMuonVetoCluster0p4_Me1112Veto = {}\n",
    "dphiMet_cluster = {}\n",
    "\n",
    "cscRechitClusterEta = {}\n",
    "cscRechitClusterNStation10  = {}\n",
    "cscRechitClusterAvgStation10 = {}\n",
    "\n",
    "sel_ev = {}\n",
    "bdt_sel = {}\n",
    "sel_csc = {}\n",
    "sel_dt = {}\n",
    "\n",
    "ggZH_weight = {}\n",
    "higgsEta = {}\n",
    "higgsPt = {}\n",
    "\n",
    "\n",
    "cluster_index = '3'\n",
    "\n",
    "NStation_weight = {}\n",
    "AvgStation_weight = {}\n",
    "Eta_weight = {}\n",
    "\n",
    "\n",
    "for k in list(tree.keys())+['data_oot_sr', 'data_oot_vr', 'data_intime_vr','data_intime_sr']:\n",
    "    if 'data' in k:continue\n",
    "#     if not k == 'data_intime_sr':continue\n",
    "########### SELECTION: CLUSTERS ############\n",
    "    if 'data' in k: T = tree['data']\n",
    "    else: T = tree[k]\n",
    "\n",
    "    sel_rechitcluster = np.abs(T.array('cscRechitCluster' + cluster_index + 'Eta')) < 2.0\n",
    "    \n",
    "    me1112_veto = 0\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberPlus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberPlus12') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberMinus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberMinus12') <= me1112_veto)\n",
    "    \n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + '_match_MB1Seg_0p4') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + '_match_RE12_0p4') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + '_match_RB1_0p4') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'TimeSpread') <= 20)\n",
    "\n",
    "    if 'oot' in k:\n",
    "        \n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster,  T.array('cscRechitCluster' + cluster_index + 'TimeTotal') < -12.5)\n",
    "    else:\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster, np.logical_and(T.array('cscRechitCluster' + cluster_index + 'TimeTotal') < 12.5, T.array('cscRechitCluster' + cluster_index + 'TimeTotal') > -5.0))\n",
    "\n",
    "\n",
    "    sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'JetVetoPt') < JET_PT_CUT)\n",
    "    sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'MuonVetoPt') < MUON_PT_CUT)\n",
    "\n",
    "\n",
    "########### SELECTION: JETS ############\n",
    "    \n",
    "    sel_jet = np.logical_and(T.array('jetPt') > jetPt_cut, np.abs(T.array('jetEta')) < 2.4 )\n",
    "    sel_jet = np.logical_and(T.array('jetTightPassId'), sel_jet)\n",
    "\n",
    "########### SELECTION: EVENTS ############\n",
    "\n",
    "    sel_ev[k] = T.array('METNoMuTrigger')\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('metEENoise') >= 200)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k], T.array('category') == 0)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('nLeptons') == 0)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] , sel_jet.sum()>=1)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k],sel_rechitcluster.sum() >= 1)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k], (T.array('nDtRings')+T.array('nCscRings'))<10)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k],T.array('Flag2_all'))\n",
    "    \n",
    "########### BRANCHES ############\n",
    "\n",
    "    \n",
    "    ##### bdt variables ####\n",
    "\n",
    "    cscRechitClusterNStation10[k] = T.array('cscRechitCluster' + cluster_index + 'NStation10')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEta[k] = T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterAvgStation10[k] = T.array('cscRechitCluster' + cluster_index + 'AvgStation10')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    \n",
    "    if len(cscRechitClusterAvgStation10[k])>0:\n",
    "        if cut_based:     \n",
    "            if cut_based_version == 'v4':\n",
    "                cond2 = np.logical_and(np.abs(cscRechitClusterAvgStation10[k])==2, np.abs(cscRechitClusterEta[k]) < 1.6)\n",
    "                cond3 = np.logical_and(np.abs(cscRechitClusterAvgStation10[k])==3, np.abs(cscRechitClusterEta[k]) < 1.6)\n",
    "                cond4 = np.logical_and(np.abs(cscRechitClusterAvgStation10[k])==4, np.abs(cscRechitClusterEta[k]) < 1.8)\n",
    "                cond1 = np.logical_and(cscRechitClusterNStation10[k]==1, np.logical_or(np.logical_or(np.abs(cscRechitClusterAvgStation10[k])==1, cond2), np.logical_or(cond3, cond4)))\n",
    "                cond2 = np.logical_and(cscRechitClusterNStation10[k] > 1, np.abs(cscRechitClusterEta[k]) < 1.9)\n",
    "                bdt_sel[k] = np.logical_or(np.logical_or(cond1, cond2), np.logical_or(cond3, cond4))\n",
    "            else:\n",
    "                print(\"CUT BASED ERROR\")\n",
    "            if 'vr' in k:\n",
    "                bdt_sel[k] = np.logical_not(bdt_sel[k])\n",
    "        else:\n",
    "            print('bdt based')\n",
    "            if k == 'data_oot_sr':\n",
    "                bdt_sel[k] = bdt_score[k] >= BDT_CUT\n",
    "            elif 'vr' in k:\n",
    "                bdt_sel[k] = bdt_score[k] < BDT_CUT            \n",
    "            elif k == 'data':\n",
    "                bdt_sel[k] = bdt_score[k] < BDT_CUT \n",
    "            else:\n",
    "                bdt_sel[k] = bdt_score[k] >= BDT_CUT\n",
    "#         print(\"effiency\",np.count_nonzero(bdt_sel[k])/len(bdt_sel[k]))\n",
    "\n",
    "        dphiMet_cluster[k] = np.abs(T.array('cscRechitCluster' + cluster_index + 'MetEENoise_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()[bdt_sel[k]]\n",
    "\n",
    "\n",
    "\n",
    "        higgsPt[k] = T.array('gHiggsPt')[sel_ev[k]][bdt_sel[k]]\n",
    "        higgsEta[k] = T.array('gHiggsEta')[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "\n",
    "        \n",
    "        ggZH_weight[k]=h_reweight.values[np.argmax(h_reweight.edges[0]>higgsPt[k][:,None],axis=1)-1, np.argmax(h_reweight.edges[1]>np.abs(higgsEta[k])[:,None],axis=1)-1]\n",
    "\n",
    "\n",
    "        if 'ggH' in k: weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('higgsPtWeight')*T.array('metSF'))[sel_ev[k]][bdt_sel[k]]\n",
    "        else:weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('metSF'))[sel_ev[k]][bdt_sel[k]]\n",
    "        if 'ggZH' in k: weight[k] *= ggZH_weight[k]\n",
    "        nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] = T.array('cscRechitCluster' + cluster_index + 'Size')[sel_rechitcluster][sel_ev[k]][bdt_sel[k]][:,0]\n",
    "       \n",
    "        \n",
    "\n",
    "       \n",
    "        NStation_weight[k] = np.ones(cscRechitClusterNStation10[k].shape)*NStation_ratio[0]\n",
    "        NStation_weight[k][cscRechitClusterNStation10[k]>1] = NStation_ratio[1]\n",
    "        \n",
    "        AvgStation_weight[k] = np.ones(cscRechitClusterAvgStation10[k].shape)*AvgStation_ratio[0]\n",
    "        AvgStation_weight[k][np.abs(cscRechitClusterAvgStation10[k])==2] = AvgStation_ratio[1]\n",
    "        AvgStation_weight[k][np.abs(cscRechitClusterAvgStation10[k])==3] = AvgStation_ratio[2]\n",
    "        AvgStation_weight[k][np.abs(cscRechitClusterAvgStation10[k])==4] = AvgStation_ratio[3]\n",
    "        AvgStation_weight[k][cscRechitClusterNStation10[k]>1] = 1\n",
    "\n",
    "\n",
    "        Eta_weight[k] = np.ones(cscRechitClusterEta[k].shape)*Eta_ratio[0]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>0.8, np.abs(cscRechitClusterEta[k])>0.9)] = Eta_ratio[0]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>0.9, np.abs(cscRechitClusterEta[k])>1.0)] = Eta_ratio[1]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.0, np.abs(cscRechitClusterEta[k])>1.1)] = Eta_ratio[2]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.1, np.abs(cscRechitClusterEta[k])>1.2)] = Eta_ratio[3]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.2, np.abs(cscRechitClusterEta[k])>1.3)] = Eta_ratio[4]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.3, np.abs(cscRechitClusterEta[k])>1.4)] = Eta_ratio[5]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.4, np.abs(cscRechitClusterEta[k])>1.5)] = Eta_ratio[6]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.5, np.abs(cscRechitClusterEta[k])>1.6)] = Eta_ratio[7]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.6, np.abs(cscRechitClusterEta[k])>1.7)] = Eta_ratio[8]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.7, np.abs(cscRechitClusterEta[k])>1.8)] = Eta_ratio[9]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.8, np.abs(cscRechitClusterEta[k])>1.9)] = Eta_ratio[10]\n",
    "        Eta_weight[k][np.logical_and(np.abs(cscRechitClusterEta[k])>1.9, np.abs(cscRechitClusterEta[k])>2.0)] = Eta_ratio[11]\n",
    "\n",
    "        if not 'data' in k:\n",
    "            sel_dt[k] = np.logical_and(np.abs(T.array('gLLP_decay_vertex_z')) < 661, np.abs(T.array('gLLP_decay_vertex_r')) > 380)\n",
    "            sel_dt[k] = np.logical_and(sel_dt[k], np.abs(T.array('gLLP_decay_vertex_r')) <738 )\n",
    "            sel_dt[k] = np.sum(sel_dt[k], axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "#             sel_dt[k] = np.logical_and(np.sum(sel_dt[k], axis = 1), T.array('nCscRechitClusters3'))[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "\n",
    "\n",
    "            sel_csc[k] = np.logical_and(np.abs(T.array('gLLP_eta') < 2.4), np.abs(T.array('gLLP_decay_vertex_r')) < 738)\n",
    "            sel_csc[k] = np.logical_and(sel_csc[k], np.abs(T.array('gLLP_decay_vertex_z')) < 1100 )\n",
    "            sel_csc[k] = np.logical_and(sel_csc[k], np.abs(T.array('gLLP_decay_vertex_z')) > 661 )\n",
    "\n",
    "\n",
    "            me11 = np.logical_and(np.abs(T.array('gLLP_eta') < 2.4), np.abs(T.array('gLLP_decay_vertex_r')) < 270)\n",
    "            me11 = np.logical_and(me11, np.abs(T.array('gLLP_decay_vertex_z')) < 661 )\n",
    "            me11 = np.logical_and(me11, np.abs(T.array('gLLP_decay_vertex_z')) > 500 )\n",
    "\n",
    "            sel_csc[k] = np.logical_or(sel_csc[k], me11)\n",
    "#             sel_csc[k] = np.sum(sel_csc[k], axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "            sel_csc[k] = np.logical_and(np.sum(sel_csc[k], axis = 1)==2, T.array('nCscRechitClusters3')>=2)[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "        if 'data' in k:\n",
    "            NStation_weight[k] = NStation_weight[k]*0.0+1\n",
    "            AvgStation_weight[k] = NStation_weight[k]*0.0 +1\n",
    "    \n",
    "\n",
    "#         print(k, np.count_nonzero(sel_csc[k]==2)/len(sel_csc[k]), np.count_nonzero(sel_dt[k]==2)/len(sel_csc[k]), np.count_nonzero(np.logical_and(sel_csc[k]== 1, sel_dt[k] == 1))/len(sel_csc[k]))\n",
    "        sel_rechitcluster2 = np.logical_and(T.array('cscRechitCluster' + cluster_index + 'TimeTotal') < 12.5,  T.array('cscRechitCluster' + cluster_index + 'TimeTotal') > -5)\n",
    "#         sel_rechitcluster2 = np.logical_and(sel_rechitcluster2,  T.array('cscRechitCluster' + cluster_index + 'MuonVetoPt')<20)\n",
    "#         sel_rechitcluster2 = np.logical_and(sel_rechitcluster2,  T.array('cscRechitCluster' + cluster_index + 'JetVetoPt')<10)\n",
    "\n",
    "        sel_rechitcluster2 = np.logical_and(sel_rechitcluster2,  T.array('cscRechitCluster' + cluster_index + 'TimeSpread') <= 20)\n",
    "\n",
    "        sel_rechitcluster2 = np.logical_and(sel_rechitcluster2,  T.array('cscRechitCluster' + cluster_index + '_match_gLLP'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(k, '\\t', np.count_nonzero(sel_csc[k])/len(sel_csc[k]))\n",
    "\n",
    "\n",
    "    else:\n",
    "        dphiMet_cluster[k] = np.abs(T.array('cscRechitCluster' + cluster_index + 'Met_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "        if 'ggH' in k:weight[k] = (T.array('weight')*T.array('pileupWeight')*T.array('higgsPtWeight'))[sel_ev[k]]\n",
    "        else:weight[k] = (T.array('weight')*T.array('pileupWeight'))[sel_ev[k]]\n",
    "        if 'data' in k:weight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "        nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] =  T.array('cscRechitCluster' + cluster_index + 'Size')[sel_rechitcluster][sel_ev[k]][:,0]\n",
    "      \n",
    "        print(\"no BDT applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal yield summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 \t 11.38009\t9.15606\t1.25177\t0.12023\n",
      "15 \t 5.08477\t13.44223\t2.84293\t0.23879\n",
      "40 \t 0.16552\t13.75263\t8.57757\t1.00537\n",
      "55 \t 0.0\t6.50017\t10.75385\t1.50686\n"
     ]
    }
   ],
   "source": [
    "ctaus = [ '100', '1000','10000','100000' ]\n",
    "\n",
    "\n",
    "BR = 0.01\n",
    "N_RECHIT_CUT = 130\n",
    "DPHI_CUT = 0.75\n",
    "corrections = 0.8953452999999999\n",
    "\n",
    "# corrections = 0.902012765\n",
    "var = dphiMet_cluster\n",
    "# DPHI_CUT = 0.6      \n",
    "# var = jetMet_dPhiMin30\n",
    "for N_RECHIT_CUT in np.arange(60,220,10):\n",
    "    if not N_RECHIT_CUT==130:continue\n",
    "    total_sig = 0\n",
    "    for m in mass:\n",
    "#         if not m == 55:continue\n",
    "        signal_rate = []\n",
    "        unc_rate = []\n",
    "        signal_unc = []\n",
    "        for ct in ctaus:   \n",
    "#             if not ct == '1000':continue\n",
    "            signal = 0\n",
    "            sig_unc = 0\n",
    "            shape_unc_temp = 0\n",
    "            ctf = int(ct)\n",
    "            if ctf < OLD_CTAU[0]:\n",
    "                old_ctau_temp = np.array([OLD_CTAU[0]])\n",
    "            else:\n",
    "                for j, ct0 in enumerate(OLD_CTAU):\n",
    "                    if ct0 == ctf: \n",
    "                        old_ctau_temp = np.array([int(ctf)])\n",
    "                        break\n",
    "\n",
    "                    elif ct0 > ctf:\n",
    "                        old_ctau_temp = np.array([OLD_CTAU[j-1], OLD_CTAU[j]])\n",
    "                        old_ctau_temp = np.array([OLD_CTAU[j]])\n",
    "                        break\n",
    "                    if j == len(OLD_CTAU)-1: \n",
    "                        old_ctau_temp = np.array([OLD_CTAU[j]])\n",
    "\n",
    "            weight_sum = 0\n",
    "            weight_len = 0\n",
    "            for j,ct0 in enumerate(old_ctau_temp):\n",
    "                prods = ['ggH', 'VBFH','WH','ZH','ttH_H','ggZH']\n",
    "                for p in prods:\n",
    "                    \n",
    "                    k = 'MC_'+p+'_'+str(m)+'_'+str(ct0)+''\n",
    "                    \n",
    "\n",
    "                    T = tree[k]\n",
    "                    if np.count_nonzero(sel_ev[k]) == 0: continue\n",
    "                    gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                    if len(gLLP_ctau) == 0: continue\n",
    "\n",
    "                    w = weight[k]*AvgStation_weight[k][bdt_sel[k]]*NStation_weight[k][bdt_sel[k]]\n",
    "                    w = weight[k]\n",
    "                    # higgs pt, signal uncertainty weight\n",
    "                    cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, np.abs(var[k])<DPHI_CUT)#bin D\n",
    "\n",
    "                    signal += np.sum(w[cond])\n",
    "#                     signal += np.count_nonzero(cond)\n",
    "#                     print(np.mean(w[cond]))\n",
    "                    sig_unc +=np.sum(w[cond]*w[cond])\n",
    "#                     shape_unc_temp = (shape_unc_temp**2+np.sum(w[cond]*shape_unc[cond])**2)**0.5\n",
    "\n",
    "\n",
    "            signal_rate.append(signal)\n",
    "            signal_unc.append(sig_unc**0.5)\n",
    "            unc_rate.append(shape_unc_temp)\n",
    "        signal_rate = np.array(signal_rate)\n",
    "        unc_rate = np.array(unc_rate)\n",
    "        signal_unc = np.array(signal_unc)\n",
    "#         print(N_RECHIT_CUT, '\\t', signal_rate[0]*BR)\n",
    "#         print(m,'GeV &', ' & '.join(map(str, [round(num,1) for num in signal_rate*BR*corrections])),'\\\\\\\\')\n",
    "#         print(m,'GeV &', ' & '.join(map(str, [round(num,1) for num in signal_rate*limit[m]])),'\\\\\\\\')\n",
    "\n",
    "#         print(m, '\\t', '\\t'.join(map(str, [round(num,2) for num in signal_unc*BR])))\n",
    "        print(m, '\\t', '\\t'.join(map(str, [round(num,5) for num in signal_rate*BR*corrections])))\n",
    "#         print(m, '\\t', '\\t'.join(map(str, [round(num,1) for num in signal_rate*BR])))\n",
    "\n",
    "\n",
    "#         print(m, '\\t', '\\t'.join(map(str, [round(num,2) for num in signal_unc*BR])))\n",
    "\n",
    "\n",
    "#         print(m, '\\t'.join(map(str,[round(num,2) for num in unc_rate*BR]))) #signal mc relative uncertainty\n",
    "        total_sig += np.sum(signal_rate)\n",
    "#         print(np.sum(signal_rate*BR))\n",
    "# print(total_sig*BR)\n",
    "\n",
    "#     print(m, '\\t'.join(map(str,unc_rate/signal_rate))) #signal mc relative uncertainty\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jetVeto = {}\n",
    "muonVeto = {}\n",
    "rechitVeto = {}\n",
    "cut_based_eff_unc = {}\n",
    "clusterEff_unc = {}\n",
    "higgsPtWeight = {}\n",
    "JES = {}\n",
    "pileup = {}\n",
    "# ctau_reweight = {}\n",
    "mc_stats = {}\n",
    "scaling = {}\n",
    "lumi = {}\n",
    "time_spread = {}\n",
    "time = {}\n",
    "theory = {}\n",
    "pdf = {}\n",
    "readout = {}\n",
    "ggH_higgsPt , VBFH_higgsPt , WH_higgsPt , ZH_higgsPt , ttH_higgsPt , ggZH_higgsPt =({} for i in range(6)) \n",
    "ggH_qcdScale , VBFH_qcdScale , WH_qcdScale , ZH_qcdScale , ttH_qcdScale , ggZH_qcdScale =({} for i in range(6)) \n",
    "ggH_pdf , VBFH_pdf , WH_pdf , ZH_pdf , ttH_pdf , ggZH_pdf =({} for i in range(6)) \n",
    "Nrechit_weight_file = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_9_4_4/src/llp_analyzer/data/Uncertainties/Nrechit_weight.txt'\n",
    "\n",
    "cut_based_unc = [0.0921, 0.0852] # muon Eta reweighted\n",
    "clustering_unc = [0.1506, 0.1047]\n",
    "\n",
    "for m in mass:\n",
    "    for ct in OLD_CTAU:\n",
    "        for p in prod:\n",
    "            if p == 'others':k = 'MC_ggH_'+str(m)+'_'+str(ct)   \n",
    "            else:k = 'MC_'+p+'_'+str(m)+'_'+str(ct)         \n",
    "            if p == 'others': key = 'MC_others_'+str(m)+'_'+str(ct)   \n",
    "            else: key = k\n",
    "\n",
    "\n",
    "            lumi[key] = [0.018]*4\n",
    "            jetVeto[key] = [0.00068]*4\n",
    "            muonVeto[key] = [0.045]*4\n",
    "            rechitVeto[key] = [0.001]*4\n",
    "            time[key] = [0.009]*4\n",
    "            time_spread[key] = [0.028]*4\n",
    "            clusterEff_unc[key]  = [0.035] * 4 #shifting Nrechit cut from 130 to 135\n",
    "            cut_based_eff_unc[key]=[0.051]*4 #muon eta reweighted\n",
    "            readout[key]=[0.01]*4 \n",
    "            JES[key] = [0.084,0.083,0.042,0.041]\n",
    "            pileup[key] = [0.008, 0.0110, 0.0110, 0.0110]\n",
    "            \n",
    "\n",
    "            ggH_higgsPt[key], VBFH_higgsPt[key], WH_higgsPt[key] , ZH_higgsPt[key] , ttH_higgsPt[key] , ggZH_higgsPt[key] = ([0.0]*8,)*6\n",
    "            ggH_qcdScale[key], VBFH_qcdScale[key], WH_qcdScale[key] , ZH_qcdScale[key] , ttH_qcdScale[key] , ggZH_qcdScale[key] = ([0.0]*8,)*6\n",
    "            ggH_pdf[key] , VBFH_pdf[key] , WH_pdf[key] , ZH_pdf[key] , ttH_pdf[key] , ggZH_pdf[key] = ([0.0]*4,)*6\n",
    "            if 'ggH' in key: \n",
    "                ggH_higgsPt[key] = [0.205, 0.205,0.207,0.208, 0.133,0.133,0.134,0.134] #down*4/up*4\n",
    "                ggH_qcdScale[key] = [0.067]*4+[0.046]*4 #down/up\n",
    "                ggH_pdf[key] = [0.032]*4\n",
    "\n",
    "            elif 'VBFH' in key: \n",
    "                VBFH_higgsPt[key] = [0.046, 0.159, 0.007, 0.006, 0.022, 0.032, 0.012, 0.010] #down/up\n",
    "                VBFH_qcdScale[key] = [0.003]*4+[0.004]*4 #down/up\n",
    "                VBFH_pdf[key] = [0.021]*4\n",
    "            elif 'ggZH' in key:\n",
    "                ggZH_higgsPt[key] = [0.194, 0.198, 0.208, 0.208, 0.120, 0.123, 0.134, 0.133] #down/up,ggZH\n",
    "                ggZH_qcdScale[key] = [0.251]*4+[0.189]*4 #down/up\n",
    "                ggZH_pdf[key] = [0.024]*4\n",
    "#                 scaling[key] = [0.2]*4\n",
    "            elif 'ZH' in key: \n",
    "                ZH_higgsPt[key] = [0.125, 0.057, 0.01, 0.017, 0.033,0.018, 0.006, 0.006] #down/up\n",
    "                ZH_qcdScale[key] = [0.006]*4+[0.005]*4 #down/up\n",
    "                ZH_pdf[key] = [0.019]*4\n",
    "            elif 'WH' in key: \n",
    "                WH_higgsPt[key] = [0.071,0.040, 0.003, 0.054, 0.026, 0.024, 0.004, 0.018] #down/up\n",
    "                WH_qcdScale[key] = [0.007]*4+[0.005]*4 #down/up\n",
    "                WH_pdf[key] = [0.019]*4\n",
    "            elif 'ttH' in key: \n",
    "                ttH_higgsPt[key] = [0.012, 0.148, 0.051, 0.028, 0.007, 0.066, 0.016, 0.010] #down/up\n",
    "                ttH_qcdScale[key] = [0.092]*4+[0.058]*4 #down/up\n",
    "                ttH_pdf[key] = [0.036]*4\n",
    "            mc_stats[k] = []\n",
    "            if p == 'ggZH': scaling[key] = [0.2]*4\n",
    "            else: scaling[key] = [0,0,0,0]\n",
    "\n",
    "\n",
    "sig_eff = [lumi, muonVeto, jetVeto,rechitVeto,time, time_spread, cut_based_eff_unc, clusterEff_unc,readout, JES,pileup, \\\n",
    "           ggH_higgsPt, VBFH_higgsPt, WH_higgsPt, ZH_higgsPt, ttH_higgsPt, ggZH_higgsPt,  \\\n",
    "           ggH_qcdScale, VBFH_qcdScale, WH_qcdScale, ZH_qcdScale, ttH_qcdScale, ggZH_qcdScale, \\\n",
    "           ggH_pdf,VBFH_pdf, WH_pdf, ZH_pdf, ttH_pdf, ggZH_pdf,\\\n",
    "           scaling, mc_stats]\n",
    "sig_eff_name = ['lumi','muonVeto','jetVeto','rechitVeto','time','time_spread','cut_based_eff_unc', 'clusterEff_unc', 'readout', 'JES','pileup', \\\n",
    "                'ggH_higgsPt', 'VBFH_higgsPt', 'WH_higgsPt', 'ZH_higgsPt', 'ttH_higgsPt', 'ggZH_higgsPt',\\\n",
    "                'ggH_qcdScale', 'VBFH_qcdScale', 'WH_qcdScale', 'ZH_qcdScale', 'ttH_qcdScale', 'ggZH_qcdScale', \\\n",
    "                'ggH_pdf','VBFH_pdf', 'WH_pdf', 'ZH_pdf', 'ttH_pdf', 'ggZH_pdf',\\\n",
    "                'ggZH_reweight','mc_stats']\n",
    "\n",
    "\n",
    "assert(len(sig_eff)==len(sig_eff_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8953452999999999\n"
     ]
    }
   ],
   "source": [
    "signal_correction = (1-0.015)*(1-0.033)*(1-0.060)\n",
    "print(signal_correction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import importlib\n",
    "importlib.reload(sys.modules['helper'])\n",
    "from helper import make_datacard, make_datacard_2sig, weight_calc\n",
    "#methodB use oot vr and ABCD method\n",
    "#methodC use the fit functions\n",
    "N_RECHIT_CUTS = np.arange(60,220, 10)\n",
    "# N_RECHIT_CUTS = [130]\n",
    "ctaus = ['5','10','15','20','30','40', '50','60', '100', '125','150','200','300','500','600','700','800','900','1000', '2000','3000','4000', '5000', '6000','7000','8000','10000', '20000','30000','50000',\\\n",
    "         '100000', '200000', '300000', '500000', '1000000', '2000000', '3000000', '5000000', '6000000', '10000000'] #mm\n",
    "UNBLIND = 2\n",
    "# 0 use OOT region, 1 unblind ABC, 2 unblind ABCD\n",
    "method = 2\n",
    "fit_function = 'se' #se, me, sp\n",
    "jetmet=0\n",
    "datacard_version  = 'v13'\n",
    "# v9 split the 3 theory uncertainties for each production mode\n",
    "if datacard_version == 'v1':\n",
    "    bkg_unc = 1.0\n",
    "    sig_unc0 = 0.2\n",
    "elif datacard_version == 'v2':\n",
    "    bkg_unc = 0.5\n",
    "    sig_unc0 = 0.2\n",
    "elif datacard_version == 'v3':\n",
    "    bkg_unc = 1.0\n",
    "    sig_unc0 = 0.3\n",
    "elif datacard_version == 'v4':#used non-closure+stat error for background\n",
    "    bkg_unc = 0.0\n",
    "    sig_unc0 = 0.2\n",
    "elif datacard_version == 'v5':#used stat error for background\n",
    "    bkg_unc = 0.0\n",
    "    sig_unc0 = 0.2\n",
    "elif datacard_version == 'v11' or datacard_version=='v12':\n",
    "    bkg_unc = [] #ABCD closure, sum of stats from two VR\n",
    "    bkg_unc_name = ['ABCD']\n",
    "elif datacard_version == 'v13': # no bkg uncertainty\n",
    "    bkg_unc = [] #ABCD closure, sum of stats from two VR\n",
    "    bkg_unc_name = []\n",
    "else:\n",
    "    bkg_unc = [] #list of two uncertainty, each element is N for the gamma uncertainty distriubtion, alpha is calculated in the makr_datacard method\n",
    "    bkg_unc_name = ['ABCD_intimeVR', 'ABCD_OOTSR']\n",
    "    print(\"ERROR in uncertainty assignment\")\n",
    "if jetmet: \n",
    "    var = jetMet_dPhiMin30\n",
    "    DPHI_CUT = 0.6\n",
    "    DPHI_CUTS = [0.6]\n",
    "else: \n",
    "    var = dphiMet_cluster\n",
    "    DPHI_CUT = 0.75\n",
    "    DPHI_CUTS = [0.75]\n",
    "\n",
    "# print(bdtBkgEff_nrechit.shape)\n",
    "bkg = []\n",
    "print(N_RECHIT_CUTS)\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "    if not N_RECHIT_CUT==130:continue\n",
    "    for DPHI_CUT in DPHI_CUTS:\n",
    "        bkg_unc = []\n",
    "        ##### method B (use OOT high BDT region and tha ratio between intime and OOT)#####\n",
    "        if not datacard_version == 'v13':\n",
    "            k = 'data_intime_vr'\n",
    "            a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "            b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT)) \n",
    "            c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "            d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "            pred = a*c/b\n",
    "            if datacard_version == 'v4': \n",
    "                unc = (abs(d-pred)/pred)**2+pred/pred**2\n",
    "            elif datacard_version == 'v11' or datacard_version=='v12':\n",
    "                bkg_unc.append(pred)\n",
    "            else:\n",
    "                bkg_unc.append(1./pred**0.5) # only the statistical uncertainty(relative)\n",
    "            factor = len(var['data_intime_vr'])/len(var['data_oot_vr'])\n",
    "            k = 'data_oot_sr'\n",
    "            a = factor * np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "            b = factor * np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT)) \n",
    "            c = factor * np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "            d = factor * np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "\n",
    "            pred = a*c/b\n",
    "            if datacard_version == 'v4': \n",
    "                bkg_unc = (unc + (abs(d-pred)/pred)**2+pred/pred**2)**0.5\n",
    "            elif datacard_version == 'v11' or datacard_version=='v12':\n",
    "                bkg_unc[0] += pred/factor # only the statistical uncertainty(relative)\n",
    "                bkg_unc[0] = 1./(bkg_unc[0]**0.5)\n",
    "            else:\n",
    "                bkg_unc.append(1./(pred/factor)**0.5) # only the statistical uncertainty(relative)\n",
    "        bkg_rate = np.array([a,b,c,pred])\n",
    "        observation = bkg_rate\n",
    "        if UNBLIND > 0 :\n",
    "            k = 'data_intime_sr'\n",
    "            a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "            b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT)) \n",
    "            c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "            d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "            bkg_rate = np.array([a,b,c,a*c/b])\n",
    "            if UNBLIND == 1:observation= np.array([a,b,c,a*c/b])\n",
    "            else: observation= np.array([a,b,c,d])\n",
    "        print(N_RECHIT_CUT, observation, bkg_unc)\n",
    "        \n",
    "        #####\n",
    "        # a = c*c1*c2\n",
    "        # b = c1* c\n",
    "        # c = c\n",
    "        # d = c2*c\n",
    "        # start adding signal\n",
    "        #####\n",
    "        outDataCardsDir = '/storage/user/christiw/login-1/christiw/LLP/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine/datacards/'+\\\n",
    "        ntupler_version+analyzer_version+'/'\n",
    "        if cut_based:outDataCardsDir += 'cut_based_'+cut_based_version+'/'\n",
    "        else: outDataCardsDir += bdt_name+'/'\n",
    "        outDataCardsDir += datacard_version+'/methodB/'\n",
    "        if UNBLIND == 0: outDataCardsDir += 'blind/'\n",
    "        elif UNBLIND == 1: outDataCardsDir += 'unblindABC/'\n",
    "        else:outDataCardsDir += 'unblind/'\n",
    "        if not os.path.isdir(outDataCardsDir):os.makedirs(outDataCardsDir)\n",
    "        print(outDataCardsDir)\n",
    "        sig_norm = []\n",
    "        for m in mass:\n",
    "            for ct in ctaus:\n",
    "                dphi = str(DPHI_CUT).replace(\".\", \"p\")\n",
    "                if len(prod) == 5: modelName = 'allProd_HToSSTo'+decay\n",
    "                elif len(prod) ==6:  modelName = 'allProd_withggZH_HToSSTo'+decay\n",
    "                else: modelName = ('_').join(prod)+'_HToSSTo'+decay\n",
    "                modelName = modelName + '_mh125_mx'+str(m)+'_ctau'+str(ct)+'mm_nRechit'+str(N_RECHIT_CUT)+'dPhiCluster'+dphi\n",
    "                \n",
    "                signal_rate = {}\n",
    "                mc_stat_unc = {}\n",
    "                gmn = {}\n",
    "                sig_unc = {}\n",
    "                ctf = int(ct)\n",
    "                ct_list = 10**int(math.log10(ctf))\n",
    "                if ctf < OLD_CTAU[0]: ct_list = [OLD_CTAU[0]]\n",
    "                elif ctf>OLD_CTAU[-1]: ct_list = [OLD_CTAU[-1]]\n",
    "                elif ct_list == int(ct): ct_list = [int(ct)]\n",
    "                else:ct_list = [ct_list,ct_list*10]\n",
    "                for p in prod:                    \n",
    "                    signal_rate[p] = np.zeros((4,))\n",
    "                    mc_stat_unc[p] = np.zeros((4,))\n",
    "                    gmn[p] = np.zeros((4,))\n",
    "                    sig_unc[p] = []\n",
    "                    if p == 'others':\n",
    "                        for i in range(4):\n",
    "                            signal_rate[p][i] = signal_rate['ggH'][i]*0.52\n",
    "                            mc_stat_unc[p][i] = (mc_stat_unc['ggH'][i]*signal_rate[p][i])**2\n",
    "                    else:\n",
    "                        for i, ct0 in enumerate(ct_list):\n",
    "                            k = 'MC_'+p+'_'+str(m)+'_'+str(ct0)\n",
    "                            T = tree[k]\n",
    "                            if np.count_nonzero(sel_ev[k])==0:continue\n",
    "#                             gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                            gLLP_ctau = T.array('gLLP_ctau')[sel_ev[k]][bdt_sel[k]]\n",
    "\n",
    "                            weight_ctau = weight_calc(gLLP_ctau, int(ct)/10, int(ct0)/10) # convert everything to cm\n",
    "                            gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                            if len(ct_list) == 1:weight_cond = gLLP_ctau >= 0\n",
    "                            else:\n",
    "                                if i == 0 : weight_cond = gLLP_ctau<int(ct_list[0]/2)\n",
    "                                else: weight_cond = gLLP_ctau>=int(ct_list[0]/2)\n",
    "                            w = weight[k]*weight_ctau\n",
    "                            cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]>=DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][0]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][0]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][0] += len(w[cond])\n",
    "                            cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]>=DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][1]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][1]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][1] += len(w[cond])\n",
    "                            cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]<DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][2]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][2]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][2] += len(w[cond])\n",
    "                            cond = np.logical_and(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]<DPHI_CUT), weight_cond)\n",
    "                            signal_rate[p][3]+=np.sum(w[cond])\n",
    "                            mc_stat_unc[p][3]+=np.sum(w[cond]**2)\n",
    "                            gmn[p][3] += len(w[cond])\n",
    "                            # apply the corrections\n",
    "                            for j in [0,1,2,3]:\n",
    "                                if signal_rate[p][j]<0.0:\n",
    "                                    signal_rate[p][j]=0.0\n",
    "                                    mc_stat_unc[p][j]=0.0\n",
    "                                    gmn[p][j] = 0.0\n",
    "                                else:\n",
    "                                    signal_rate[p][j] *= signal_correction\n",
    "\n",
    "#                     mc_stat_unc[p] = list(np.nan_to_num(np.sqrt(mc_stat_unc[p])/signal_rate[p])) #convert absolute to relative uncertainty\n",
    "                    \n",
    "                    mc_stat_unc[p] = np.nan_to_num(signal_rate[p]/np.sqrt(mc_stat_unc[p]))**2 #gmn\n",
    "                    mc_stat_unc[p][mc_stat_unc[p] == np.inf] = 0.0\n",
    "                    \n",
    "                    mc_stat_unc[p] = list(mc_stat_unc[p])\n",
    "                    mc_stat_unc[p] = list(gmn[p])\n",
    "                    if p == 'others': k = k.replace(\"ggH\", \"others\")\n",
    "                    for j, ele in enumerate(sig_eff):# go through each uncertainty\n",
    "                        if j == len(sig_eff)-1: # if mc_stats\n",
    "                            sig_unc[p].append(mc_stat_unc[p])\n",
    "#                         elif sig_eff_name[j] in simulation_name:\n",
    "# #                             print(type(ele[k]))\n",
    "#                             sig_unc[p].append(np.array(ele[k])*0.5)\n",
    "                        else:\n",
    "                            sig_unc[p].append(ele[k])\n",
    "                   \n",
    "                \n",
    "                norm = np.sum(signal_rate['ggH'])/4\n",
    "                if norm == 0.0:continue\n",
    "                sig_norm.append(norm)\n",
    "\n",
    "                for k,v in signal_rate.items():signal_rate[k] = v/norm\n",
    "                print(modelName, norm, signal_rate['ggH'], mc_stat_unc['ggH'])\n",
    "                make_datacard_2sig(outDataCardsDir, modelName, signal_rate, norm, bkg_rate, observation, \\\n",
    "                                  bkg_unc, bkg_unc_name, sig_unc, sig_eff_name)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unblind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'data_intime_sr'\n",
    "\n",
    "n_ev = 5000\n",
    "var = np.abs(dphiMet_cluster[k])\n",
    "DPHI_CUT = 0.75\n",
    "print(\"Nrechits, A, B, C, pred, D\")\n",
    "for N_RECHIT_CUT in np.arange(60,240,10):\n",
    "    a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var>=DPHI_CUT))\n",
    "    b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var>=DPHI_CUT))\n",
    "    c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var<DPHI_CUT))\n",
    "    d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var<DPHI_CUT))\n",
    "    pred = c/b*a\n",
    "    unc_pred = (1./c + 1./b + 1./a)**0.5*(c/b*a)\n",
    "\n",
    "    print(N_RECHIT_CUT, '\\t',a,'\\t',b,'\\t',c,'\\t',d,'\\t', round(c/b*a, 2), '\\t',\\\n",
    "          round( (1./c + 1./b + 1./a)**0.5*(c/b*a), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
