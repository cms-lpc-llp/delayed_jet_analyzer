{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/02\n",
      "3.6.8 (default, Aug  7 2019, 17:28:10) \n",
      "[GCC 4.8.5 20150623 (Red Hat 4.8.5-39)]\n"
     ]
    }
   ],
   "source": [
    "# use OOT data to estimate bkg in signal region\n",
    "import ROOT as rt\n",
    "# import root_numpy as rtnp\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import collections\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import uproot\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import awkward\n",
    "import numpy as np\n",
    "import time\n",
    "import numba\n",
    "from numba import jit\n",
    "from matplotlib import pyplot as plt\n",
    "sys.path.append('/storage/user/christiw/gpu/christiw/llp/delayed_jet_analyzer/lib/')\n",
    "from histo_utilities import create_TH1D, create_TH2D, std_color_list, create_TGraph, make_ratio_plot\n",
    "import CMS_lumi, tdrstyle\n",
    "tdrstyle.setTDRStyle()\n",
    "CMS_lumi.writeExtraText = 0\n",
    "wH = 1\n",
    "Z_MASS = 91.2\n",
    "# donotdelete = []\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath =OrderedDict()\n",
    "tree = OrderedDict()\n",
    "old_ctau = OrderedDict()\n",
    "# mass = [15]\n",
    "# VBFH = 0\n",
    "# decay = 'dddd'\n",
    "\n",
    "# mass = [7, 15, 40, 55]\n",
    "# VBFH=1\n",
    "# decay = 'bbbb'\n",
    "lumi = 137000\n",
    "ntupler_version = 'V1p17/'\n",
    "analyzer_version = 'v1/v9'\n",
    "data_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/' + ntupler_version + '/Data2018/v5/v9/normalized/'\n",
    "sig_path = '/mnt/hadoop/store/group/phys_exotica/delayedjets/displacedJetMuonAnalyzer/csc/' + ntupler_version +\\\n",
    "'/MC_Fall18/' + analyzer_version + '/normalized/'\n",
    "\n",
    "fpath['data'] = data_path + 'Run2_displacedJetMuonNtupler_V1p17_Data2016_Data2017_Data2018-HighMET_goodLumi.root'\n",
    "fpath['MC_ggH_HToSS_SToEE_ms0p1_pl500'] = sig_path +'ggH_HToSS_SToEE_ms0p1_pl500_1pb_weighted.root' \n",
    "fpath['MC_ggH_HToSS_SToPi0Pi0_ms1_pl500'] = sig_path + 'ggH_HToSS_SToPi0Pi0_ms1_pl500_1pb_weighted.root'\n",
    "fpath['MC_ggH_HToSS_SToPiPlusPiMinus_ms1_pl500'] = sig_path + 'ggH_HToSS_SToPiPlusPiMinus_ms1_pl500_1pb_weighted.root'\n",
    "fpath['MC_ggH_HToSS_SToKPlusKMinus_ms1p5_pl500'] = sig_path + 'ggH_HToSS_SToKPlusKMinus_ms1p5_pl500_1pb_weighted.root'\n",
    "fpath['MC_ggH_HToSSTobbbb_ms1_pl1000'] = sig_path +  'ggH_HToSSTobbbb_ms1_pl1000_1pb_weighted.root'\n",
    "fpath['MC_ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000'] = sig_path +  'ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root'\n",
    "fpath['MC_ggH_HToSS_SToEE_ms0p4_pl500'] = sig_path + 'ggH_HToSS_SToEE_ms0p4_pl500_1pb_weighted.root'\n",
    "fpath['MC_ggH_HToSSTo4Tau_MH-125_MS-7_ctau-1000'] = sig_path +  'ggH_HToSSTo4Tau_MH-125_MS-7_ctau-1000_TuneCP5_13TeV-powheg-pythia8_1pb_weighted.root'\n",
    "old_ctau['MC_ggH_HToSS_SToEE_ms0p4_pl500'] = 500\n",
    "old_ctau['MC_ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000'] = 1000\n",
    "old_ctau['MC_ggH_HToSSTo4Tau_MH-125_MS-7_ctau-1000'] = 1000\n",
    "old_ctau['MC_ggH_HToSSTobbbb_ms1_pl1000'] = 1000\n",
    "old_ctau['MC_ggH_HToSS_SToKPlusKMinus_ms1p5_pl500'] = 500\n",
    "old_ctau['MC_ggH_HToSS_SToPiPlusPiMinus_ms1_pl500'] = 500\n",
    "old_ctau['MC_ggH_HToSS_SToPi0Pi0_ms1_pl500'] = 500\n",
    "old_ctau['MC_ggH_HToSS_SToEE_ms0p1_pl500'] = 500\n",
    "\n",
    "NEvents = {}\n",
    "NEvents_genweight = {}\n",
    "for k,v in fpath.items():\n",
    "    root_dir = uproot.open(v) \n",
    "    if not root_dir: \n",
    "        print(k, \"zombie\")\n",
    "        continue\n",
    "    tree[k] = root_dir['MuonSystem']\n",
    "    NEvents[k] = root_dir['NEvents'][1]\n",
    "    w = tree[k][\"weight\"].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt_name = \"cut_based_v4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nCsc with different hit vetoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut based\n",
      "9941\n",
      "data effiency 0.29366602687140114\n",
      "117\n",
      "MC_ggH_HToSS_SToEE_ms0p1_pl500 effiency 0.83\n",
      "110\n",
      "MC_ggH_HToSS_SToPi0Pi0_ms1_pl500 effiency 0.8817204301075269\n",
      "205\n",
      "MC_ggH_HToSS_SToPiPlusPiMinus_ms1_pl500 effiency 0.9058823529411765\n",
      "249\n",
      "MC_ggH_HToSS_SToKPlusKMinus_ms1p5_pl500 effiency 0.9205607476635514\n",
      "106\n",
      "MC_ggH_HToSSTobbbb_ms1_pl1000 effiency 0.8865979381443299\n",
      "1667\n",
      "MC_ggH_HToSSTobbbb_MH-125_MS-15_ctau-1000 effiency 0.9195979899497487\n",
      "58\n",
      "MC_ggH_HToSS_SToEE_ms0p4_pl500 effiency 0.8571428571428571\n",
      "988\n",
      "MC_ggH_HToSSTo4Tau_MH-125_MS-7_ctau-1000 effiency 0.8850855745721271\n",
      "13124\n",
      "data_oot_sr effiency 0.32528504359490273\n",
      "13124\n",
      "data_oot_vr effiency 0.6747149564050973\n",
      "9941\n",
      "data_intime_vr effiency 0.7063339731285988\n",
      "CPU times: user 49.9 s, sys: 4.89 s, total: 54.8 s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_t = time.time()\n",
    "JET_PT_CUT = 10.0\n",
    "MUON_PT_CUT = 20.0\n",
    "N_RECHIT_CUT = 90\n",
    "jetPt_cut = 50\n",
    "tightid = False\n",
    "ring_cut = 50\n",
    "if bdt_name == 'bdt_flatten_metfilter_me1112nohits_eta2p0_testsize0p2_noSpread_v2':\n",
    "    BDT_CUT = 0.2983932 \n",
    "    bdtBkgEff = 0.34527687296416937\n",
    "    BDT_BINS = [0.0, BDT_CUT]\n",
    "elif \"cut_based\" in bdt_name:\n",
    "    print(\"cut based\")\n",
    "else:\n",
    "    print('BDT NAME NOT FOUND')\n",
    "DPHI_CUT = 1\n",
    "weight = {}\n",
    "weight_event = {}\n",
    "weight_ctau = {}\n",
    "lumiSec = {}\n",
    "evtNum = {}\n",
    "nCsc = {}\n",
    "npv = {}\n",
    "npu = {}\n",
    "runNum = {}\n",
    "nCsc_JetMuonVetoCluster0p4_Me1112Veto = {}\n",
    "gLLP_csc = {}\n",
    "cscClusterSize = {}\n",
    "met = {}\n",
    "pileupWeight = {}\n",
    "gLLP_ctau = {}\n",
    "npv = {}\n",
    "nRechitClusters = {}\n",
    "nJets = {}\n",
    "nJets_50gev = {}\n",
    "cscRechitClusterTimeDiff = {}\n",
    "cscRechitCluster_match_gLLP = {}\n",
    "higgsPtWeight = {}\n",
    "cscRechitClusterNStation = {}\n",
    "cscRechitClusterAvgStation = {}\n",
    "cscRechitClusterNStation10  = {}\n",
    "cscRechitClusterAvgStation10 = {}\n",
    "cscRechitClusterEta = {}\n",
    "jetMet_dPhiMin30 = {}\n",
    "dphiMet_cluster = {}\n",
    "jetMet_dPhiMin30_sr = {}\n",
    "sel_ev = {}\n",
    "bdt_sel = {}\n",
    "sf_facScaleUp = {}\n",
    "sf_facScaleDown = {}\n",
    "sf_renScaleUp = {}\n",
    "sf_renScaleDown = {}\n",
    "sf_facRenScaleUp = {}\n",
    "sf_facRenScaleDown = {}\n",
    "cluster_index = '3'\n",
    "\n",
    "for k in list(tree.keys()) + ['data_oot_sr', 'data_oot_vr', 'data_intime_vr']:\n",
    "########### SELECTION: CLUSTERS ############\n",
    "    if 'data' in k: T = tree['data']\n",
    "    else: T = tree[k]\n",
    "    sel_rechitcluster = np.abs(T.array('cscRechitCluster' + cluster_index + 'Eta')) < 2.0\n",
    "    me1112_veto = 0\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberPlus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberPlus12') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberMinus11') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'NRechitChamberMinus12') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + '_match_MB1Seg_0p4') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + '_match_RE12_0p4') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + '_match_RB1_0p4') <= me1112_veto)\n",
    "    sel_rechitcluster = np.logical_and(sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'TimeSpread') <= 20)\n",
    "    if 'oot' in k:\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster,  T.array('cscRechitCluster' + cluster_index + 'TimeTotal') < -12.5)\n",
    "    else:\n",
    "        sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'JetVetoPt') < JET_PT_CUT)\n",
    "        sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'MuonVetoPt') < MUON_PT_CUT)\n",
    "        sel_rechitcluster = np.logical_and(sel_rechitcluster, np.logical_and(T.array('cscRechitCluster' + cluster_index + 'TimeTotal') < 12.5, T.array('cscRechitCluster' + cluster_index + 'TimeTotal') > -5.0))\n",
    "    sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'JetVetoPt') < JET_PT_CUT)\n",
    "    sel_rechitcluster = np.logical_and( sel_rechitcluster, T.array('cscRechitCluster' + cluster_index + 'MuonVetoPt') < MUON_PT_CUT)\n",
    "    print(np.count_nonzero(sel_rechitcluster.flatten()))\n",
    "\n",
    "########### SELECTION: JETS ############\n",
    "    \n",
    "    sel_jet = np.logical_and(T.array('jetPt') > jetPt_cut, np.abs(T.array('jetEta')) < 2.4 )\n",
    "\n",
    "########### SELECTION: EVENTS ############\n",
    "    hlt = T['HLTDecision'].array()\n",
    "    sel_ev[k]  = hlt[:,310]\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('met') > 200)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k], T.array('category') == 0)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] ,T.array('nLeptons') == 0)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k] , sel_jet.sum()>=1)\n",
    "    sel_ev[k]  = np.logical_and(sel_ev[k],sel_rechitcluster.sum() == 1)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k], (T.array('nDtRings')+T.array('nCscRings'))<10)\n",
    "    sel_ev[k] = np.logical_and(sel_ev[k],T.array('Flag2_all'))\n",
    "    gLLP_csc[k] = np.sum(T.array('gLLP_csc'),axis = 1)\n",
    "    if 'MC' in k:\n",
    "        sel_ev[k] = np.logical_and(sel_ev[k], np.sum(T.array('gLLP_csc'),axis = 1) > 0)\n",
    "\n",
    "########### BRANCHES ############\n",
    "    \n",
    "    ##### bdt variables ####\n",
    "    cscRechitClusterNStation[k] = T.array('cscRechitCluster' + cluster_index + 'NStation5')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterNStation10[k] = T.array('cscRechitCluster' + cluster_index + 'NStation10')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterAvgStation[k] = T.array('cscRechitCluster' + cluster_index + 'AvgStation5')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterAvgStation10[k] = T.array('cscRechitCluster' + cluster_index + 'AvgStation10')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    cscRechitClusterEta[k] = T.array('cscRechitCluster' + cluster_index + 'Eta')[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "    if len(cscRechitClusterNStation[k])>0:\n",
    "        if bdt_name == 'cut_based_v4':\n",
    "            cond2 = np.logical_and(np.abs(cscRechitClusterAvgStation10[k])==2, np.abs(cscRechitClusterEta[k]) < 1.6)\n",
    "            cond3 = np.logical_and(np.abs(cscRechitClusterAvgStation10[k])==3, np.abs(cscRechitClusterEta[k]) < 1.6)\n",
    "            cond4 = np.logical_and(np.abs(cscRechitClusterAvgStation10[k])==4, np.abs(cscRechitClusterEta[k]) < 1.8)\n",
    "            cond1 = np.logical_and(cscRechitClusterNStation10[k]==1, np.logical_or(np.logical_or(np.abs(cscRechitClusterAvgStation10[k])==1, cond2), np.logical_or(cond3, cond4)))\n",
    "            cond2 = np.logical_and(cscRechitClusterNStation10[k] > 1, np.abs(cscRechitClusterEta[k]) < 1.9)\n",
    "            bdt_sel[k] = np.logical_or(np.logical_or(cond1, cond2), np.logical_or(cond3, cond4))\n",
    "            if 'vr' in k: bdt_sel[k] = np.logical_not(bdt_sel[k])\n",
    "        else:\n",
    "            print(\"CUT BASED ERROR\")\n",
    "            \n",
    "        print(k, \"effiency\",np.count_nonzero(bdt_sel[k])/len(bdt_sel[k]))\n",
    "\n",
    "        dphiMet_cluster[k] = np.abs(T.array('cscRechitCluster' + cluster_index + 'Met_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()[bdt_sel[k]]\n",
    "        jetMet_dPhiMin30[k] = T.array('jetMet_dPhiMin')[sel_ev[k]][bdt_sel[k]]\n",
    "        weight[k] = T.array('weight')[sel_ev[k]][bdt_sel[k]]\n",
    "        npv[k] = T.array('npv')[sel_ev[k]][bdt_sel[k]]\n",
    "        if k[:2] == 'MC':\n",
    "            pileupWeight[k] = T.array('pileupWeight')[sel_ev[k]][bdt_sel[k]]\n",
    "            higgsPtWeight[k] = T.array('higgsPtWeight')[sel_ev[k]][bdt_sel[k]]\n",
    "            sf_facScaleUp[k] = T.array('sf_facScaleUp')[sel_ev[k]][bdt_sel[k]]\n",
    "            sf_facScaleDown[k] = T.array('sf_facScaleDown')[sel_ev[k]][bdt_sel[k]]\n",
    "            sf_renScaleUp[k] = T.array('sf_renScaleUp')[sel_ev[k]][bdt_sel[k]]\n",
    "            sf_renScaleDown[k] = T.array('sf_renScaleDown')[sel_ev[k]][bdt_sel[k]]\n",
    "            sf_facRenScaleUp[k] = T.array('sf_facRenScaleUp')[sel_ev[k]][bdt_sel[k]]\n",
    "            sf_facRenScaleDown[k] = T.array('sf_facRenScaleDown')[sel_ev[k]][bdt_sel[k]]\n",
    "        else:\n",
    "            pileupWeight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            higgsPtWeight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            sf_facScaleUp[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            sf_facScaleDown[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            sf_renScaleUp[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            sf_renScaleDown[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            sf_facRenScaleUp[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "            sf_facRenScaleDown[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "        if k[:2] == 'MC':\n",
    "            weight[k] = weight[k]*lumi\n",
    "        cscClusterSize[k] =  T.array('cscRechitCluster' + cluster_index + 'Size')[sel_rechitcluster][sel_ev[k]][bdt_sel[k]]\n",
    "        nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] = cscClusterSize[k][:,0]\n",
    "    else:\n",
    "        dphiMet_cluster[k] = np.abs(T.array('cscRechitCluster' + cluster_index + 'Met_dPhi'))[sel_rechitcluster][sel_ev[k]][:,0].flatten()\n",
    "        weight[k] = T.array('weight')[sel_ev[k]]\n",
    "        npv[k] = T.array('npv')[sel_ev[k]]\n",
    "        if k[:2] == 'MC':\n",
    "            pileupWeight[k] = T.array('pileupWeight')[sel_ev[k]]\n",
    "        else:\n",
    "            pileupWeight[k] = np.ones(weight[k].shape, dtype=bool)\n",
    "        if k[:2] == 'MC':\n",
    "            weight[k] = weight[k]*lumi\n",
    "        cscClusterSize[k] =  T.array('cscRechitCluster' + cluster_index + 'Size')[sel_rechitcluster][sel_ev[k]]\n",
    "        nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] = cscClusterSize[k][:,0]\n",
    "        print(\"no BDT applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# life time reweight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_calc(llp_ct, new_ctau, old_ctau):\n",
    "    source = np.exp(-1.0*llp_ct/old_ctau)/old_ctau**2\n",
    "    weight = 1.0/new_ctau**2 * np.exp(-1.0*llp_ct/new_ctau)/source\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# signal yield summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 \t [8.40250201 8.21504909 2.73673316]\n",
      "130 \t [8.75538566 8.83315917 2.90749692]\n",
      "130 \t [14.17254653 13.8102358   5.90590637]\n",
      "130 \t [20.63312417 17.82346115  8.42351777]\n",
      "130 \t [11.33924911 13.36205253  5.42943824]\n",
      "130 \t [ 0.95268156  5.89833585 22.74223541]\n",
      "130 \t [3.81886442 3.77990261 1.29055732]\n",
      "130 \t [ 5.14850033 12.2400472  14.39226585]\n"
     ]
    }
   ],
   "source": [
    "ctaus = ['50', '100', '500']\n",
    "BR = 0.01\n",
    "N_RECHIT_CUT = 130\n",
    "DPHI_CUT = 0.75      \n",
    "var = dphiMet_cluster\n",
    "for N_RECHIT_CUT in np.arange(60,220,10):\n",
    "    if not N_RECHIT_CUT== 130:continue\n",
    "    for k in fpath.keys():\n",
    "        if k == 'data':continue\n",
    "        signal_rate = []\n",
    "        unc_rate = []\n",
    "        for ct in ctaus:   \n",
    "            T = tree[k]\n",
    "            gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "            if len(gLLP_ctau) == 0: continue\n",
    "            weight_ctau = weight_calc(gLLP_ctau, float(ct)/10, old_ctau[k]/10) # convert everything to cm\n",
    "            w = pileupWeight[k] * weight[k] * weight_ctau * higgsPtWeight[k]\n",
    "            cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]<DPHI_CUT)\n",
    "            signal_rate.append(np.sum(w[cond]))\n",
    "        signal_rate = np.array(signal_rate)\n",
    "        print(N_RECHIT_CUT, '\\t', signal_rate*BR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 18.480063018117708\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "70 10.209173031983537\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "80 5.480385976821995\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "90 3.6158839470382316\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "100 2.893374217969022\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "110 1.5991482797205838\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "120 1.0845975360773366\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "130 0.6896646785950961\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "140 0.49000427145350706\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "150 0.09793209248446332\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "160 0.09793209248446332\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "170 0.09889221103823254\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "180 0.09889221103823254\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "190 0.09889221103823254\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "200 0.09889221103823254\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n",
      "210 0.09889221103823254\n",
      "directory exists! /storage/user/gdituri/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/V1p17/v1/v9/cut_based_v4/v1/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "N_RECHIT_CUTS = np.arange(60,220, 10)\n",
    "\n",
    "ctaus = ['5','10','20', '30','40', '50','60','80', '100','200','300','500', '1000', '5000'] #mm\n",
    "datacard_version  = 'v1'\n",
    "bkg_unc = 1.0\n",
    "sig_unc0 = 0.2\n",
    "\n",
    "var = dphiMet_cluster\n",
    "DPHI_CUTS = [0.75]\n",
    "\n",
    "for N_RECHIT_CUT in N_RECHIT_CUTS:\n",
    "    for DPHI_CUT in DPHI_CUTS:\n",
    "        ##### method B #####\n",
    "        factor = len(var['data_intime_vr'])/len(var['data_oot_vr'])\n",
    "        k = 'data_oot_sr'\n",
    "        a = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] >= DPHI_CUT))\n",
    "        b = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] >= DPHI_CUT)) \n",
    "        c = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] < N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "        d = np.count_nonzero(np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k] >= N_RECHIT_CUT, var[k] < DPHI_CUT)) \n",
    "        pred = a*c/b\n",
    "        stat_unc = (1./a + 1./c + 1./b)**0.5*(pred)\n",
    "        sys_unc = abs(d-pred)\n",
    "        unc = [a**0.5/a, b**0.5/b, c**0.5/c, (stat_unc**2 + sys_unc**2)**0.5/pred]\n",
    "        a = a * factor\n",
    "        b = b * factor\n",
    "        c = c * factor\n",
    "        d = d * factor\n",
    "        pred = pred * factor\n",
    "        observation = np.array([a,b,c,pred])\n",
    "        print(N_RECHIT_CUT, pred)\n",
    "        \n",
    "        #####\n",
    "        # a = c*c1*c2\n",
    "        # b = c1* c\n",
    "        # c = c\n",
    "        # d = c2*c\n",
    "        #####\n",
    "\n",
    "        outDataCardsDir = os.environ['HOME']+'/login-1/CMSSW_10_2_13/src/HiggsAnalysis/MuonSystemLimit/combine_gdituri/datacards/'+\\\n",
    "        ntupler_version+analyzer_version+'/'+ bdt_name+'/'+datacard_version+'/'\n",
    "       # open(outDataCardsDir)\n",
    "        if not os.path.isdir(outDataCardsDir):\n",
    "            os.makedirs(outDataCardsDir)\n",
    "            print(\"made new directory: \",outDataCardsDir)\n",
    "        else:\n",
    "            print(\"directory exists!\", outDataCardsDir)\n",
    "        sig_norm = []\n",
    "        for k in fpath.keys():\n",
    "            if k == 'data':continue\n",
    "            for ct in ctaus:\n",
    "                dphi = str(DPHI_CUT).replace(\".\", \"p\")\n",
    "                modelName = k[3:]\n",
    "                modelName = modelName + '_ctau'+str(ct)+'mm_nRechit'+str(N_RECHIT_CUT)+'dPhiCluster'+dphi\n",
    "                signal_rate = np.zeros((4,))\n",
    "                sig_unc =  np.zeros((4,))\n",
    "\n",
    "                T = tree[k]\n",
    "                gLLP_ctau = np.sum(T.array('gLLP_ctau'), axis = 1)[sel_ev[k]][bdt_sel[k]]\n",
    "                if len(gLLP_ctau) == 0: continue\n",
    "\n",
    "                weight_ctau = weight_calc(gLLP_ctau, float(ct)/10, old_ctau[k]/10) # convert everything to cm\n",
    "                w = pileupWeight[k] * weight[k] * weight_ctau * higgsPtWeight[k]\n",
    "\n",
    "                cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]>=DPHI_CUT)\n",
    "                signal_rate[0] =np.sum(w[cond])\n",
    "                cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]>=DPHI_CUT)\n",
    "                signal_rate[1]=np.sum(w[cond])\n",
    "                cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]<N_RECHIT_CUT, var[k]<DPHI_CUT)\n",
    "                signal_rate[2]=np.sum(w[cond])\n",
    "                cond = np.logical_and(nCsc_JetMuonVetoCluster0p4_Me1112Veto[k]>=N_RECHIT_CUT, var[k]<DPHI_CUT)\n",
    "                signal_rate[3]=np.sum(w[cond])\n",
    "\n",
    "                norm = np.sum(signal_rate)\n",
    "                sig_norm.append(norm)\n",
    "                make_datacard(outDataCardsDir, modelName, False, signal_rate/norm, norm, observation, bkg_unc, np.array([sig_unc0, sig_unc0, sig_unc0, sig_unc0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datacard(outDataCardsDir,modelName, jetmet, signal_rate, norm, observation, unc, sig_unc):\n",
    "    a,b,c,d = observation[0], observation[1], observation[2], observation[3]\n",
    "    if jetmet:\n",
    "        c1 = b/c\n",
    "        c2 = d/c\n",
    "    else:\n",
    "        c1 = a/b\n",
    "        c2 = c/b\n",
    "    text_file = open(outDataCardsDir+modelName+\".txt\", \"w\")\n",
    "    text_file.write('# signal norm {0} \\n'.format(norm))\n",
    "\n",
    "    text_file.write('imax {0} \\n'.format(4))\n",
    "    text_file.write('jmax {0} \\n'.format(1))\n",
    "    text_file.write('kmax * \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('--------------- \\n')\n",
    "    text_file.write('bin \\t chA \\t chB \\t chC \\t chD \\n')\n",
    "    text_file.write('observation \\t {0:6.2f} \\t {1:6.2f} \\t {2:6.2f} \\t {3:6.2f} \\n'.format(a, b, c, d))\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    text_file.write('bin \\t chA \\t chA \\t chB \\t chB \\t chC \\t chC \\t chD \\t chD \\n')\n",
    "    text_file.write('process sig \\t bkg \\t sig \\t bkg \\t sig \\t bkg \\t sig \\t bkg \\n')\n",
    "    text_file.write('process 0 \\t 1 \\t 0 \\t 1 \\t 0 \\t 1 \\t 0 \\t 1 \\n')\n",
    "    rate_string = 'rate'\n",
    "    for i, rate in enumerate(signal_rate):\n",
    "        rate_string =  rate_string+'\\t {0:e} \\t 1'.format(rate)\n",
    "    text_file.write(rate_string+'\\n')\n",
    "    text_file.write('------------------------------ \\n')  \n",
    "    for ch in ['A','B','C','D']:\n",
    "        text_file.write('NA\\t rateParam \\t ch{0} \\t bkg \\t {1:6.2f} \\n'.format(ch, c))\n",
    "    if jetmet:\n",
    "        text_file.write('c1\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "        text_file.write('c1\\t rateParam \\t chB \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "    else:\n",
    "        text_file.write('c1\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chD \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "        text_file.write('c1\\t rateParam \\t chA \\t bkg \\t {0:e} \\n'.format(c1))\n",
    "        text_file.write('c2\\t rateParam \\t chC \\t bkg \\t {0:e} \\n'.format(c2))\n",
    "#     #### uncertainties ####\n",
    "    text_file.write('lumi\\t lnN \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\t 1.025000 \\t - \\n')\n",
    "    text_file.write('signal_yield \\t lnN  \\t {0} \\t - \\t {1} \\t - \\t {2} \\t - \\t {3} \\t -\\n'.format(1+sig_unc[0], 1+sig_unc[1], 1+sig_unc[2], 1+sig_unc[3]))    \n",
    "#     if jetmet:\n",
    "#         text_file.write('ABCD_closure \\t lnN \\t - \\t {0} \\t - \\t {1} \\t - \\t {2} \\t - \\t {3} \\n'.format(1+unc[0], 1+unc[1], 1+unc[2], 1+unc[3]))\n",
    "#     else:\n",
    "#         text_file.write('ABCD_closure \\t lnN \\t - \\t {0} \\t - \\t {1} \\t - \\t {2} \\t - \\t {3} \\n'.format(1+unc[0], 1+unc[1], 1+unc[2], 1+unc[3]))\n",
    "\n",
    "    if jetmet:\n",
    "        text_file.write('ABCD_closure \\t lnN \\t - \\t {0} \\t - \\t - \\t - \\t - \\t - \\t - \\n'.format(1+unc))\n",
    "    else:\n",
    "        text_file.write('ABCD_closure \\t lnN \\t - \\t - \\t - \\t - \\t - \\t - \\t - \\t {0} \\n'.format(1+unc))\n",
    "\n",
    "    \n",
    "    text_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
